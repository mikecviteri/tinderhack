{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **6 de marzo: Bot que pueda dar likes con base a belleza**\n",
    "* **10 de marzo: Análisis de sentimiento de las descripciones**\n",
    "* 13 de marzo: Acceder a cookies y sacar info. relevante para modelo de la persona / **ENTRENAR CON MATCHES EXISTENTES**\n",
    "* 17 de marzo: Conectar todo\n",
    "* 20 de marzo: Tener lista formas de mejorar el modelo y que vaya aprendiendo con retro del usuario\n",
    "* 23 de marzo: Carpeta que arroje los insights más importantes\n",
    "* 24 de marzo: Presentación\n",
    "* 25 de marzo: Script\n",
    "* 26 de marzo: Ensayo \n",
    "\n",
    "Empezar entrenando con matches existentes, guardándolos en una base de datos, nombre, edad, descripción, km distancia, ubicación ,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fotos proteger\n",
    "#nombres tokenizados con descripciones en formato json\n",
    "#implicitly wait\n",
    "#collab: run time a gpu\n",
    "#frases distancia coseno descripción matches que gustan a ti\n",
    "#levenstein\n",
    "#preclasificar embudo ver inst desc\n",
    "\n",
    "#descargar todas las imagenes en un folder por persona con un token especifico\n",
    "#ligar esa columna para un ovr score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "import math\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from time import sleep\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import randint\n",
    "from secrets import username, password\n",
    "import PIL.Image\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import glob\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "\n",
    "chrome_options.add_argument('--incognito')\n",
    "chrome_options.add_argument(\"--disable-infobars\")\n",
    "chrome_options.add_argument(\"start-maximized\")\n",
    "chrome_options.add_argument(\"--disable-extensions\")\n",
    "chrome_options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "prefs = {\n",
    "    'profile.default_content_setting_values':\n",
    "    {\n",
    "        'notifications': 1,\n",
    "        'geolocation': 1\n",
    "    },\n",
    "\n",
    "    'profile.managed_default_content_settings':\n",
    "    {\n",
    "        'geolocation': 1\n",
    "    },\n",
    "}\n",
    "\n",
    "chrome_options.add_experimental_option('prefs', prefs)\n",
    "\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.get('https://tinder.com')\n",
    "\n",
    "\n",
    "assert \"Tinder\" in driver.title\n",
    "\n",
    "#Click en login\n",
    "sleep(randint(1,5))\n",
    "log_in = driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div/div/header/div/div[2]/div[2]/button')\n",
    "log_in.click()\n",
    "\n",
    "sleep(randint(1,5))\n",
    "\n",
    "#Ir al pop up\n",
    "driver.switch_to_alert\n",
    "\n",
    "sleep(randint(1,5))\n",
    "\n",
    "#Click en login de Facebook\n",
    "fb_button = driver.find_element_by_xpath('.//div/div/div[1]/div/div[3]/span/div[2]/button/span[2]')\n",
    "fb_button.click()\n",
    "\n",
    "window_before = driver.window_handles[0]\n",
    "window_after = driver.window_handles[1]\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "driver.switch_to_window(window_after)\n",
    "\n",
    "user_in = driver.find_element_by_xpath('//*[@id=\"email\"]')\n",
    "user_in.send_keys(username)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "\n",
    "pass_in = driver.find_element_by_xpath('//*[@id=\"pass\"]')\n",
    "pass_in.send_keys(password)\n",
    "\n",
    "login_btn = driver.find_element_by_xpath('/html/body/div/div[2]/div[1]/form/div/div[3]/label[2]/input')\n",
    "login_btn.click()\n",
    "\n",
    "driver.switch_to_window(window_before)\n",
    "\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath('.//div/div/div/div/div[3]/button[1]/span').click()\n",
    "except:\n",
    "    try:\n",
    "        driver.find_element_by_xpath('/html/body/div[2]/div/div/div/div/div[3]/button[1]').click()\n",
    "    except:\n",
    "        print('No se pudo quitar popup 1')\n",
    "        pass\n",
    "\n",
    "sleep(1.2)\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath('.//div/div/div/div/div[3]/button[1]').click()\n",
    "except:\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@id=\"t--1610880557\"]/div/div/div/div/div[3]/button[1]').click()\n",
    "    except:\n",
    "        print('No se pudo quitar popup 2')\n",
    "        pass\n",
    "    \n",
    "sleep(1.6)\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_xpath('.//div/div[2]/div/div/div[1]/button').click()\n",
    "except:\n",
    "    try:\n",
    "        driver.find_element_by_xpath('/html/body/div[1]/div/div[2]/div/div/div[1]/button').click()\n",
    "    except:\n",
    "        print('No se pudo quitar popup 3')\n",
    "        pass\n",
    "\n",
    "# login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths\n",
    "left = f\"{os.getcwd()}/Photos/Left\"\n",
    "right = f\"{os.getcwd()}/Photos/Right\"\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "#work = soup.find(\"path\", {\"d\": \"M7.15 3.434h5.7V1.452a.728.728 0 0 0-.724-.732H7.874a.737.737 0 0 0-.725.732v1.982z\"})\n",
    "work = 'M7.15 3.434h5.7V1.452a.728.728 0 0 0-.724-.732H7.874a.737.737 0 0 0-.725.732v1.982z'\n",
    "\n",
    "# education = soup.find(\"path\", {\"d\" : \"M11.87 5.026L2.186 9.242c-.25.116-.25.589 0 .705l.474.204v2.622a.78.78 0 0 0-.344.657c0 .42.313.767.69.767.378 0 .692-.348.692-.767a.78.78 0 0 0-.345-.657v-2.322l2.097.921a.42.42 0 0 0-.022.144v3.83c0 .45.27.801.626 1.101.358.302.842.572 1.428.804 1.172.46 2.755.776 4.516.776 1.763 0 3.346-.317 4.518-.777.586-.23 1.07-.501 1.428-.803.355-.3.626-.65.626-1.1v-3.83a.456.456 0 0 0-.022-.145l3.264-1.425c.25-.116.25-.59 0-.705L12.13 5.025c-.082-.046-.22-.017-.26 0v.001zm.13.767l8.743 3.804L12 13.392 3.257 9.599l8.742-3.806zm-5.88 5.865l5.75 2.502a.319.319 0 0 0 .26 0l5.75-2.502v3.687c0 .077-.087.262-.358.491-.372.29-.788.52-1.232.68-1.078.426-2.604.743-4.29.743s-3.212-.317-4.29-.742c-.444-.161-.86-.39-1.232-.68-.273-.23-.358-.415-.358-.492v-3.687z\"})\n",
    "education = 'M11.87 5.026L2.186 9.242c-.25.116-.25.589 0 .705l.474.204v2.622a.78.78 0 0 0-.344.657c0 .42.313.767.69.767.378 0 .692-.348.692-.767a.78.78 0 0 0-.345-.657v-2.322l2.097.921a.42.42 0 0 0-.022.144v3.83c0 .45.27.801.626 1.101.358.302.842.572 1.428.804 1.172.46 2.755.776 4.516.776 1.763 0 3.346-.317 4.518-.777.586-.23 1.07-.501 1.428-.803.355-.3.626-.65.626-1.1v-3.83a.456.456 0 0 0-.022-.145l3.264-1.425c.25-.116.25-.59 0-.705L12.13 5.025c-.082-.046-.22-.017-.26 0v.001zm.13.767l8.743 3.804L12 13.392 3.257 9.599l8.742-3.806zm-5.88 5.865l5.75 2.502a.319.319 0 0 0 .26 0l5.75-2.502v3.687c0 .077-.087.262-.358.491-.372.29-.788.52-1.232.68-1.078.426-2.604.743-4.29.743s-3.212-.317-4.29-.742c-.444-.161-.86-.39-1.232-.68-.273-.23-.358-.415-.358-.492v-3.687z'\n",
    "\n",
    "#gender = soup.find(\"path\", {\"d\": \"M15.507 13.032c1.14-.952 1.862-2.656 1.862-5.592C17.37 4.436 14.9 2 11.855 2 8.81 2 6.34 4.436 6.34 7.44c0 3.07.786 4.8 2.02 5.726-2.586 1.768-5.054 4.62-4.18 6.204 1.88 3.406 14.28 3.606 15.726 0 .686-1.71-1.828-4.608-4.4-6.338\"})\n",
    "gender = 'M15.507 13.032c1.14-.952 1.862-2.656 1.862-5.592C17.37 4.436 14.9 2 11.855 2 8.81 2 6.34 4.436 6.34 7.44c0 3.07.786 4.8 2.02 5.726-2.586 1.768-5.054 4.62-4.18 6.204 1.88 3.406 14.28 3.606 15.726 0 .686-1.71-1.828-4.608-4.4-6.338'\n",
    "    \n",
    "#Info\n",
    "def info_button():\n",
    "    try:\n",
    "        driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[1]/div[3]/div[3]/button').click()\n",
    "        #WebDriverWait(driver,4).until(EC.element_to_be_clickable((By.XPATH,'.//div/div[1]/div/div/main/div/div[1]/div/div[1]/div[3]/div[3]/button'))).click()\n",
    "    except:\n",
    "        try:\n",
    "            WebDriverWait(driver, 4).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[1]/div/div/main/div/div[1]/div/div[1]/div[3]/div[3]/button\"))).click()\n",
    "        except:\n",
    "            try:\n",
    "#                 actions = ActionChains(driver)\n",
    "#                 actions.send_keys(Keys.ARROW_UP)\n",
    "#                 actions.perform()\n",
    "                driver.find_element_by_xpath(\"//div[contains(.,'Open Profile')]\").click()\n",
    "            except:\n",
    "                try:\n",
    "                    driver.find_element_by_xpath(\"//div[contains(.,'Open Profile')]\").click()\n",
    "                except:\n",
    "                    #print('No se pudo entrar 3')\n",
    "                    pass\n",
    "                \n",
    "# re.findall('t-[\\d]*', ex)\n",
    "    \n",
    "def to_photo():\n",
    "    try:\n",
    "        WebDriverWait(driver,4).until(EC.element_to_be_clickable((By.XPATH, './/div/div[1]/div/main/div[1]/div/div/div[1]'\n",
    "))).click()\n",
    "    except:\n",
    "        try:\n",
    "            WebDriverWait(driver,4).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]'))).click()\n",
    "        except:\n",
    "            print('No se pudo dar click en la foto')\n",
    "            pass\n",
    "        \n",
    "def to_main():\n",
    "    try:\n",
    "        WebDriverWait(driver,4).until(EC.element_to_be_clickable((By.XPATH, './/div/div[1]/div/main'))).click()\n",
    "    except:\n",
    "        try:\n",
    "            WebDriverWait(driver,4).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[1]/div/main'))).click()\n",
    "        except:\n",
    "            try:\n",
    "                driver.find_element_by_xpath(\".//div/div[1]/div/main\").click()\n",
    "            except:\n",
    "                print('No se pudo regresar a main')\n",
    "                pass\n",
    "\n",
    "\n",
    "def get_name(soup):\n",
    "    try:\n",
    "        name = soup.h1.string\n",
    "        return name\n",
    "    except:\n",
    "        try:\n",
    "            name = soup.find(\"span\", itemprop=\"name\").text\n",
    "            return name\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def get_age(soup):\n",
    "    try:\n",
    "        age = soup.select('div [class=\"Whs(nw) Fz($l)\"]')[0].text\n",
    "        return age\n",
    "    except:\n",
    "        try:\n",
    "            age = soup.find(\"span\", itemprop=\"age\").text\n",
    "            return age\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def get_info(soup):\n",
    "    try:\n",
    "        info = soup.select('div [class=\"Row\"]')\n",
    "        all_info = [info[i].text for i in range(len(info))]\n",
    "        return all_info\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_description(soup):\n",
    "    try:\n",
    "        description = soup.select('div [class=\"P(16px) Ta(start) Us(t) C($c-secondary) BreakWord Whs(pl) Fz($ms)\"]')[0].text\n",
    "        return description\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_likes(soup):\n",
    "    try:\n",
    "        likes = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-secondary) C($c-secondary)\"]')\n",
    "        all_likes = ', '.join([likes[i].text for i in range(len(likes))])\n",
    "        return all_likes\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_similar_likes(soup):\n",
    "    try:\n",
    "        similar_likes = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-pink) C($c-pink)\"]')\n",
    "        all_similar_likes = ', '.join([similar_likes[i].text for i in range(len(similar_likes))])\n",
    "        return all_similar_likes\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "def get_photo_len(soup):\n",
    "    try:\n",
    "        photo_len = [int(i.text[-1]) for i in soup.select('div[class=\"CenterAlign D(f) Fxd(r) W(100%) Px(8px) Pos(a) TranslateZ(0)\"]')][0]\n",
    "        return photo_len\n",
    "    except:\n",
    "        #print('Error al sacar número de fotos')\n",
    "        return 1\n",
    "    \n",
    "def scrap_photos(photo_len):\n",
    "    \n",
    "    links = []\n",
    "\n",
    "    for i in range(photo_len):\n",
    "        try:\n",
    "            driver.find_element_by_xpath(f'/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]/div[1]/div/div[1]/span/div/div[2]/button[{i+1}]').click()\n",
    "        except:\n",
    "            try:\n",
    "                driver.find_element_by_xpath(f'.//div/div[1]/div/main/div[1]/div/div/div/div[2]/div/div[1]/div/div/div[1]/span/div/div[2]/button[{i+1}]').click()\n",
    "            except:\n",
    "                pass\n",
    "        sleep(2.1)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        photos = soup.select('div[class=\"profileCard__slider__img Z(-1)\"]')\n",
    "        sleep(2.5)\n",
    "        sub_links = [str(photos[i]).split('(\"', 1)[1].split('\")')[0] for i in range(len(photos))]\n",
    "        links.append(sub_links)\n",
    "    \n",
    "    flat_list = list(set([item for sublist in links for item in sublist]))\n",
    "        \n",
    "    return flat_list\n",
    "\n",
    "#Guardar jpgs\n",
    "def save_images(number):\n",
    "    for i, url in enumerate(number):\n",
    "        \n",
    "        save_webp = f'{i}.webp'\n",
    "        save_jpg = f'{i}.jpg'\n",
    "        \n",
    "        if re.findall(r'([^.]*)$', url)[0] == 'webp':\n",
    "            PIL.Image.open(f'{os.getcwd()}/{urllib.request.urlretrieve(url, save_webp)[0]}').convert(\"RGB\").save(save_jpg,\"jpeg\")\n",
    "            os.remove(save_webp)\n",
    "        \n",
    "        else:\n",
    "            urllib.request.urlretrieve(url, save_jpg)\n",
    "    \n",
    "def get_spotify(soup):\n",
    "    try:\n",
    "        if('My Anthem') in soup.select('div [class=\"P(16px)\"]')[0].text:\n",
    "            sleep(1.1)\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def get_artist(soup):\n",
    "    artist = soup.select('div [class=\"D(f) Fz($s) C($c-secondary)\"]')[0].text\n",
    "    return artist\n",
    "\n",
    "def get_song(soup):\n",
    "    song = soup.select('div [class=\"Mb(4px) Ell Fz($ms)\"]')[0].text\n",
    "    return song\n",
    "\n",
    "def get_instagram(soup):\n",
    "    try:\n",
    "        if soup.select('div [class=\"P(16px)\"] > h2')[0].text == 'Recent Instagram Photos':\n",
    "            return True\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def plot_images(number):\n",
    "    images = []\n",
    "    for img_path in glob.glob('*.jpg'):\n",
    "        images.append(mpimg.imread(img_path))\n",
    "\n",
    "    plt.figure(figsize=(20,10))\n",
    "    columns = len(number)\n",
    "\n",
    "    for i, image in enumerate(images):\n",
    "        plt.subplot(int(len(images)/columns+1), columns, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def verified(soup):\n",
    "    try:\n",
    "        icons = soup.select('div [class=\"D(ib) Lh(0) Sq(30px) Mstart(4px) As(c)\"]')\n",
    "        if len(icons) > 0:\n",
    "            for i in range(len(icons)):\n",
    "                if 'Verified!' in icons[i].text:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def super_like(soup):\n",
    "    try:\n",
    "        icons = soup.select('div [class=\"D(ib) Lh(0) Sq(30px) Mstart(4px) As(c)\"]')\n",
    "        if len(icons) > 0:\n",
    "            for i in range(len(icons)):\n",
    "                if 'Super Like' in icons[i].text:\n",
    "                    return True\n",
    "                else:\n",
    "                    return False\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "#Borrando imágenes\n",
    "def delete_images(number):\n",
    "    for i in range(len(number)):\n",
    "        del_jpg = f'{i}.jpg'\n",
    "        os.remove(del_jpg)\n",
    "        \n",
    "#Salir de info\n",
    "def info_out():\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//a[@class=\"End(12px) B(-20px) Pos(a) Z(2) CenterAlign Bdrs(50%) P(0) Scale(1.1):h Trsdu($normal) focus-button-style\"]/*[name()=\"svg\"]/*[name()=\"g\"]').click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def like_button():\n",
    "    try:\n",
    "        #Like sin salir de info\n",
    "        driver.find_element_by_xpath(\".//div/div[1]/div/main/div[1]/div/div/div[1]/div[2]/div/div/div[4]/button\").click()\n",
    "        #driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div/div/main/div/div[1]/div/div[2]/div[4]/button').click()\n",
    "    except:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[4]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                driver.find_element_by_css_selector('#t--1032254752 > div > div.App__body.H\\(100\\%\\).Pos\\(r\\).Z\\(0\\) > div > div > main > div > div.recsCardboard.W\\(100\\%\\).Mt\\(a\\).H\\(100\\%\\)--s.Px\\(4px\\)--s.Pos\\(r\\) > div > div.Pos\\(r\\).Py\\(16px\\).Py\\(12px\\)--s.Px\\(4px\\).Px\\(8px\\)--ml.D\\(f\\).Jc\\(sb\\).Ai\\(c\\).Maw\\(375px\\)--m.Mx\\(a\\).Pe\\(n\\).Mt\\(-1px\\) > div:nth-child(4) > button > span > svg').click()\n",
    "            except:\n",
    "                print('No se pudo')\n",
    "                pass\n",
    "            \n",
    "def dislike_button():\n",
    "    try:\n",
    "        #Dislike sin salir de info\n",
    "        driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/button').click()\n",
    "        #driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[2]/button').click()\n",
    "    except:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[2]/button').click()\n",
    "        except:\n",
    "            print('No se pudo')\n",
    "            pass\n",
    "        \n",
    "def close_match():\n",
    "    try:\n",
    "        driver.find_element_by_xpath('//*[@title=\"Back to Tinder\"]').click()\n",
    "        #driver.find_element_by_xpath('/html/body/div[2]/div/div/div/div/div[4]/button').click()\n",
    "    except:\n",
    "        try:\n",
    "            driver.find_element_by_xpath('.//div/div/div[1]/div/div[4]/button').click()\n",
    "#             actions = ActionChains(driver)\n",
    "#             actions.send_keys(Keys.ESCAPE)\n",
    "#             actions.perform()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "def no_super_like():\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button[2]\").click()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def match_report(soup, links, name, age, location, distance, education, school, job, orientation, likes, s_likes, desc, p_len, spotify, artist, song, verif, sup_like, insta):\n",
    "    \n",
    "    plot_images(links)\n",
    "\n",
    "    #Número de fotos\n",
    "    print(f\"{color.BOLD}Fotos: {color.END}{p_len}\")\n",
    "    print()\n",
    "    \n",
    "    #Nombre y edad\n",
    "    print(f\"{color.BOLD}Nombre: {color.END}{name}\\n{color.BOLD}Edad:{color.END} {age}\")\n",
    "    print()\n",
    "\n",
    "    #Info\n",
    "    print(f\"{color.BOLD}Location: {color.END}{location}\")\n",
    "    print(f\"{color.BOLD}Distance (km): {color.END}{distance}\")\n",
    "    print(f\"{color.BOLD}School: {color.END}{school}\")\n",
    "    print(f\"{color.BOLD}Job: {color.END}{job}\")\n",
    "    print(f\"{color.BOLD}Orientation: {color.END}{orientation}\")\n",
    "    print()\n",
    "\n",
    "    #Similar Likes\n",
    "    print(f\"{color.BOLD}Similar likes: {color.END} {s_likes}\")\n",
    "    print()\n",
    "\n",
    "    #Likes\n",
    "    print(f\"{color.BOLD}Likes: {color.END} {likes}\")\n",
    "    print()\n",
    "    \n",
    "    #Descripición\n",
    "    print(f\"{color.BOLD}Descripción: {color.END}\")\n",
    "    print(desc)\n",
    "    print()\n",
    "\n",
    "    #Perfil verificado\n",
    "    print(f'{color.BOLD}Verified:{color.END} {verif}')\n",
    "    print()\n",
    "\n",
    "    #Super like\n",
    "    print(f'{color.BOLD}Super liked me:{color.END} {sup_like}')\n",
    "    print()\n",
    "\n",
    "    #Instagram\n",
    "    print(f'{color.BOLD}Instagram:{color.END} {insta}')\n",
    "    print()\n",
    "\n",
    "    #Spotify\n",
    "    print(f'{color.BOLD}Spotify:{color.END} {spotify}')\n",
    "    print(f'{color.BOLD}Artist:{color.END} {artist}')\n",
    "    print(f'{color.BOLD}Song:{color.END} {song}')\n",
    "    print()\n",
    "    print('---------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "def prepare(wd):\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    info_button()\n",
    "    sleep(2.5)\n",
    "    \n",
    "    #Scraping de imágenes y limpieza para obtener ligas\n",
    "    actions = ActionChains(wd)\n",
    "    sopa = BeautifulSoup(wd.page_source, 'lxml')\n",
    "    sleep(2.5)\n",
    "    \n",
    "    photo_len = get_photo_len(sopa)\n",
    "    name = get_name(sopa)\n",
    "    age = get_age(sopa)\n",
    "    informacion = get_info(sopa)\n",
    "    sleep(2.5)\n",
    "    \n",
    "    info = dict.fromkeys(['location', 'distance', 'education', 'school', 'job', 'orientation'], None)\n",
    "\n",
    "    for i in range(len(informacion)):\n",
    "        if 'Lives in' in informacion[i]:\n",
    "            info['location'] = informacion[i].replace('Lives in ','')\n",
    "        if 'kilometers away' in informacion[i]:\n",
    "            info['distance'] = informacion[i].replace('kilometers away','')\n",
    "        if education in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "            info['school'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "        if work in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "            info['job'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "        if gender in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "            info['orientation'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "            \n",
    "    location = info['location']\n",
    "    distance = info['distance']\n",
    "    school = info['school']\n",
    "    job = info['job']\n",
    "    orientation = info['orientation']\n",
    "    \n",
    "    description = get_description(sopa)\n",
    "    likes = get_likes(sopa)\n",
    "    similar_likes = get_similar_likes(sopa)\n",
    "    \n",
    "    sleep(1.6)\n",
    "    \n",
    "    photo_links = scrap_photos(photo_len)\n",
    "    sleep(2)\n",
    "    save_images(photo_links)\n",
    "    sleep(2)\n",
    "    \n",
    "    \n",
    "    #Perfil verificado\n",
    "    verif = verified(sopa)\n",
    "\n",
    "    #Super like\n",
    "    sup_like = super_like(sopa)\n",
    "\n",
    "    #Instagram\n",
    "    insta = get_instagram(sopa)\n",
    "    \n",
    "    music = dict.fromkeys(['spotify', 'artist', 'song'], False)\n",
    "    \n",
    "    if get_spotify(sopa) == True:\n",
    "        music['spotify'] = True\n",
    "        music['artist'] = get_artist(sopa)\n",
    "        music['song'] = get_song(sopa)\n",
    "        \n",
    "    spotify = music['spotify']\n",
    "    artist = music['artist']\n",
    "    song = music['song']\n",
    "    \n",
    "    match_report(sopa, photo_links, name, age, location, distance, education, school, job, orientation, likes, similar_likes, description, photo_len, spotify, artist, song, verif, sup_like, insta)\n",
    "    \n",
    "    sleep(2)\n",
    "    \n",
    "    delete_images(photo_links)\n",
    "    info_out()\n",
    "    \n",
    "    atr_score = 59\n",
    "    desc_score =  0.73\n",
    "    prob_swipe = 0.54\n",
    "    ovr_score = 7\n",
    "    my_swipe = 'Left'\n",
    "    match = False\n",
    "        \n",
    "    result.append([name, age, photo_len, school, job, orientation, location, distance, similar_likes, likes, description, verif, sup_like, insta, spotify, artist, song, atr_score, desc_score, prob_swipe, ovr_score, my_swipe, match])\n",
    "    return (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados del scraping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ab = prepare(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(ab, columns = cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_super_like()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dislike_button()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA CON CLASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from time import sleep\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import randint\n",
    "from secrets import username, password\n",
    "import PIL.Image\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_seq_items = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "work = 'M7.15 3.434h5.7V1.452a.728.728 0 0 0-.724-.732H7.874a.737.737 0 0 0-.725.732v1.982z'\n",
    "education = 'M11.87 5.026L2.186 9.242c-.25.116-.25.589 0 .705l.474.204v2.622a.78.78 0 0 0-.344.657c0 .42.313.767.69.767.378 0 .692-.348.692-.767a.78.78 0 0 0-.345-.657v-2.322l2.097.921a.42.42 0 0 0-.022.144v3.83c0 .45.27.801.626 1.101.358.302.842.572 1.428.804 1.172.46 2.755.776 4.516.776 1.763 0 3.346-.317 4.518-.777.586-.23 1.07-.501 1.428-.803.355-.3.626-.65.626-1.1v-3.83a.456.456 0 0 0-.022-.145l3.264-1.425c.25-.116.25-.59 0-.705L12.13 5.025c-.082-.046-.22-.017-.26 0v.001zm.13.767l8.743 3.804L12 13.392 3.257 9.599l8.742-3.806zm-5.88 5.865l5.75 2.502a.319.319 0 0 0 .26 0l5.75-2.502v3.687c0 .077-.087.262-.358.491-.372.29-.788.52-1.232.68-1.078.426-2.604.743-4.29.743s-3.212-.317-4.29-.742c-.444-.161-.86-.39-1.232-.68-.273-.23-.358-.415-.358-.492v-3.687z'\n",
    "gender = 'M15.507 13.032c1.14-.952 1.862-2.656 1.862-5.592C17.37 4.436 14.9 2 11.855 2 8.81 2 6.34 4.436 6.34 7.44c0 3.07.786 4.8 2.02 5.726-2.586 1.768-5.054 4.62-4.18 6.204 1.88 3.406 14.28 3.606 15.726 0 .686-1.71-1.828-4.608-4.4-6.338'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors():\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "class TinderBot():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument('--incognito')\n",
    "        self.options.add_argument(\"--disable-infobars\")\n",
    "        self.options.add_argument(\"start-maximized\")\n",
    "        self.options.add_argument(\"--disable-extensions\")\n",
    "        self.options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "        prefs = {\n",
    "            'profile.default_content_setting_values':\n",
    "            {\n",
    "                'notifications': 1,\n",
    "                'geolocation': 1\n",
    "            },\n",
    "\n",
    "            'profile.managed_default_content_settings':\n",
    "            {\n",
    "                'geolocation': 1\n",
    "            },\n",
    "        }\n",
    "\n",
    "        self.options.add_experimental_option('prefs', prefs)\n",
    "        self.driver = webdriver.Chrome(options=self.options)\n",
    "    \n",
    "    def login(self):\n",
    "        self.driver.get('https://tinder.com')\n",
    "\n",
    "        assert \"Tinder\" in self.driver.title\n",
    "\n",
    "        sleep(randint(1,5))\n",
    "        log_in = self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div/div/header/div/div[2]/div[2]/button')\n",
    "        log_in.click()\n",
    "\n",
    "        sleep(randint(1,5))\n",
    "\n",
    "        self.driver.switch_to_alert\n",
    "\n",
    "        sleep(randint(1,5))\n",
    "\n",
    "        fb_button = self.driver.find_element_by_xpath('.//div/div/div[1]/div/div[3]/span/div[2]/button/span[2]')\n",
    "        fb_button.click()\n",
    "\n",
    "        window_before = self.driver.window_handles[0]\n",
    "        window_after = self.driver.window_handles[1]\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        self.driver.switch_to.window(window_after)\n",
    "\n",
    "        user_in = self.driver.find_element_by_xpath('//*[@id=\"email\"]')\n",
    "        user_in.send_keys(username)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        pass_in = self.driver.find_element_by_xpath('//*[@id=\"pass\"]')\n",
    "        pass_in.send_keys(password)\n",
    "\n",
    "        login_btn = self.driver.find_element_by_xpath('/html/body/div/div[2]/div[1]/form/div/div[3]/label[2]/input')\n",
    "        login_btn.click()\n",
    "\n",
    "        self.driver.switch_to.window(window_before)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div/div/div/div[3]/button[1]/span').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('/html/body/div[2]/div/div/div/div/div[3]/button[1]').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sleep(1.2)\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div/div/div/div[3]/button[1]').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('//*[@id=\"t--1610880557\"]/div/div/div/div/div[3]/button[1]').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sleep(1.6)\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[2]/div/div/div[1]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('/html/body/div[1]/div/div[2]/div/div/div[1]/button').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def info_button(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[1]/div[3]/div[3]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 4).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[1]/div/div/main/div/div[1]/div/div[1]/div[3]/div[3]/button\"))).click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_xpath(\"//div[contains(.,'Open Profile')]\").click()\n",
    "                except:\n",
    "                    try:\n",
    "                        self.driver.find_element_by_xpath(\"//div[contains(.,'Open Profile')]\").click()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    def to_photo(self):\n",
    "        try:\n",
    "            WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, './/div/div[1]/div/main/div[1]/div/div/div[1]'\n",
    "    ))).click()\n",
    "        except:\n",
    "            try:\n",
    "                WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]'))).click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def to_main(self):\n",
    "        try:\n",
    "            WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, './/div/div[1]/div/main'))).click()\n",
    "        except:\n",
    "            try:\n",
    "                WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[1]/div/main'))).click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_xpath(\".//div/div[1]/div/main\").click()\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    def back_to_swipe(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div/div[1]/div/div/div[1]/a/button').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def get_name(self, soup):\n",
    "        try:\n",
    "            name = soup.h1.string\n",
    "            return name\n",
    "        except:\n",
    "            try:\n",
    "                name = soup.find(\"span\", itemprop=\"name\").text\n",
    "                return name\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    def get_age(self, soup):\n",
    "        try:\n",
    "            age = soup.select('div [class=\"Whs(nw) Fz($l)\"]')[0].text\n",
    "            return age\n",
    "        except:\n",
    "            try:\n",
    "                age = soup.find(\"span\", itemprop=\"age\").text\n",
    "                return age\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    def get_info(self, soup):\n",
    "        try:\n",
    "            info = soup.select('div [class=\"Row\"]')\n",
    "            all_info = [info[i].text for i in range(len(info))]\n",
    "            return all_info\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_description(self, soup):\n",
    "        try:\n",
    "            description = soup.select('div [class=\"P(16px) Ta(start) Us(t) C($c-secondary) BreakWord Whs(pl) Fz($ms)\"]')[0].text\n",
    "            return description\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def get_likes(self, soup):\n",
    "        try:\n",
    "            lista = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-secondary) C($c-secondary)\"]')\n",
    "            if len(lista) > 0:\n",
    "                all_likes = ', '.join([lista[i].text for i in range(len(lista))])\n",
    "                return all_likes\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            pass           \n",
    "        \n",
    "    def get_similar_likes(self, soup):\n",
    "        try:\n",
    "            lista = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-pink) C($c-pink)\"]')\n",
    "            if len(lista) > 0:\n",
    "                all_similar_likes = ', '.join([lista[i].text for i in range(len(lista))])\n",
    "                return all_similar_likes\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            pass   \n",
    "\n",
    "    def get_photo_len(self, soup):\n",
    "        try:\n",
    "            photo_len = [int(i.text.strip()[-1]) for i in soup.select('div[class=\"CenterAlign D(f) Fxd(r) W(100%) Px(8px) Pos(a) TranslateZ(0)\"]')][0]\n",
    "            return photo_len\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    def scrap_photos(self, photo_len):\n",
    "\n",
    "        links = []\n",
    "\n",
    "        for i in range(photo_len):\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath(f'.//div/div[1]/div/main/div[1]/div/div/div/div[2]/div/div[1]/div/div/div[1]/span/div/div[2]/button[{i+1}]').click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_xpath(f'/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]/div[1]/div/div[1]/span/div/div[2]/button[{i+1}]').click()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            sleep(2.5)\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "            sleep(0.5)\n",
    "            photos = soup.select('div[class=\"profileCard__slider__img Z(-1)\"]')\n",
    "            sleep(0.1)\n",
    "            sub_links = [str(photos[i]).split('(\"', 1)[1].split('\")')[0] for i in range(len(photos))]\n",
    "            links.append(sub_links)\n",
    "\n",
    "        flat_list = list(set([item for sublist in links for item in sublist]))\n",
    "        return flat_list\n",
    "\n",
    "    def save_images(self, number, tag):\n",
    "        \n",
    "        path = f'{os.getcwd()}/images/{tag}'\n",
    "        os.mkdir(path)\n",
    "        \n",
    "        for i, url in enumerate(number):\n",
    "\n",
    "            save_webp = f'{path}/{i}-{tag}.webp'\n",
    "            save_jpg = f'{path}/{i}-{tag}.jpg'\n",
    "\n",
    "            if re.findall(r'([^.]*)$', url)[0] == 'webp':\n",
    "                PIL.Image.open(f'{urllib.request.urlretrieve(url, save_webp)[0]}').convert(\"RGB\").save(save_jpg,\"jpeg\")\n",
    "                sleep(0.5)\n",
    "                os.remove(save_webp)\n",
    "            else:\n",
    "                urllib.request.urlretrieve(url, save_jpg)\n",
    "\n",
    "    def get_spotify(self, soup):\n",
    "        try:\n",
    "            h2_list = [i.text for i in soup.select('div [class=\"P(16px)\"] > h2')]\n",
    "            if 'My anthem' in h2_list:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def get_artist(self, soup):\n",
    "        artist = soup.select('div [class=\"D(f) Fz($s) C($c-secondary)\"]')[0].text\n",
    "        return artist\n",
    "\n",
    "    def get_song(self, soup):\n",
    "        song = soup.select('div [class=\"Mb(4px) Ell Fz($ms)\"]')[0].text\n",
    "        return song\n",
    "\n",
    "    def get_instagram(self, soup):\n",
    "        try:\n",
    "            h2_list = [i.text for i in soup.select('div [class=\"P(16px)\"] > h2')]\n",
    "            if 'Recent Instagram photos' in h2_list:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def plot_images(self, number, tag):\n",
    "        \n",
    "        images = []\n",
    "        path = f'{os.getcwd()}/images/{tag}'\n",
    "\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for img_path in files:\n",
    "                if img_path.endswith('.jpg'):\n",
    "                    images.append(mpimg.imread(f'{path}/{img_path}'))\n",
    "\n",
    "        plt.figure(figsize=(20,10))\n",
    "        columns = len(number)\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(int(len(images)/columns+1), columns, i+1)\n",
    "            plt.imshow(image)\n",
    "            plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.show()\n",
    "     \n",
    "    def verified(self, soup):\n",
    "        try:\n",
    "            icons = soup.select('div [class=\"D(ib) Lh(0) Sq(30px) Mstart(4px) As(c)\"]')\n",
    "            if len(icons) > 0:\n",
    "                for i in range(len(icons)):\n",
    "                    if 'Verified!' in icons[i].text:\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def super_like(self, soup):\n",
    "        try:\n",
    "            icons = soup.select('div [class=\"D(ib) Lh(0) Sq(30px) Mstart(4px) As(c)\"]')\n",
    "            if len(icons) > 0:\n",
    "                for i in range(len(icons)):\n",
    "                    if 'Super Like' in icons[i].text:\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            pass          \n",
    "\n",
    "    def delete_images(self, tag):\n",
    "        path = f'{os.getcwd()}/images/{tag}'\n",
    "        os.rmdir(path)\n",
    "\n",
    "    def info_out(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//a[@class=\"End(12px) B(-20px) Pos(a) Z(2) CenterAlign Bdrs(50%) P(0) Scale(1.1):h Trsdu($normal) focus-button-style\"]/*[name()=\"svg\"]/*[name()=\"g\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def like_button(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(\".//div/div[1]/div/main/div[1]/div/div/div[1]/div[2]/div/div/div[4]/button\").click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[4]/button').click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_css_selector('#t--1032254752 > div > div.App__body.H\\(100\\%\\).Pos\\(r\\).Z\\(0\\) > div > div > main > div > div.recsCardboard.W\\(100\\%\\).Mt\\(a\\).H\\(100\\%\\)--s.Px\\(4px\\)--s.Pos\\(r\\) > div > div.Pos\\(r\\).Py\\(16px\\).Py\\(12px\\)--s.Px\\(4px\\).Px\\(8px\\)--ml.D\\(f\\).Jc\\(sb\\).Ai\\(c\\).Maw\\(375px\\)--m.Mx\\(a\\).Pe\\(n\\).Mt\\(-1px\\) > div:nth-child(4) > button > span > svg').click()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    def dislike_button(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[2]/button').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def close_match(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//*[@title=\"Back to Tinder\"]').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div/div[1]/div/div[4]/button').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def no_super_like(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button[2]\").click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def matches_button(self):\n",
    "        try:\n",
    "            mtchs_btn = self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav/div/div/div/div[1]/div/div[1]')\n",
    "            mtchs_btn.click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def get_number_of_matches(self):\n",
    "        \n",
    "        self.matches_button()\n",
    "        \n",
    "        actions = ActionChains(self.driver)\n",
    "        m = 0 \n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div[1]/div[2]/a/div[1]/div').click()\n",
    "                sleep(2)\n",
    "                self.driver.find_element_by_xpath('.//div[1]/div[2]/a/div[1]/div').click()\n",
    "                sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            actions.send_keys(Keys.END)\n",
    "            actions.perform()\n",
    "            sleep(2)\n",
    "\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "            sleep(5)\n",
    "            number_of_matches = len(soup.select('div [class=\"P(8px)\"]'))\n",
    "\n",
    "            if (number_of_matches != m):\n",
    "                m = number_of_matches\n",
    "            else:\n",
    "                return number_of_matches\n",
    "                break\n",
    "                \n",
    "        self.back_to_swipe()\n",
    "          \n",
    "    def message_button(self):\n",
    "        try:\n",
    "            msg_btn = self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav/div/div/div/div[1]/div/div[2]')\n",
    "            msg_btn.click()\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "    def get_number_of_messages(self):\n",
    "    \n",
    "        self.message_button()\n",
    "        \n",
    "        actions = ActionChains(self.driver)\n",
    "        m = 0 \n",
    "\n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav').click()\n",
    "                sleep(0.5)\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav').click()\n",
    "                sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            actions.send_keys(Keys.END)\n",
    "            actions.perform()\n",
    "            sleep(1)\n",
    "\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "            sleep(1)\n",
    "            number_of_messages = len(soup.select('div [class=\"D(f) Fx($flx1) Ov(h) Fxd(c) Pend(10px)\"]'))\n",
    "\n",
    "            if (number_of_messages != m):\n",
    "                m = number_of_messages\n",
    "            else:\n",
    "                return number_of_messages\n",
    "                break\n",
    "                \n",
    "        self.back_to_swipe()\n",
    "               \n",
    "    def matches_report(self):\n",
    "        \n",
    "        self.matches_button()\n",
    "        number = self.get_number_of_matches()\n",
    "        result = []\n",
    " \n",
    "        for i in range (1, math.ceil(number/9)+1):\n",
    "            for h in range(1, 10):\n",
    "                if (i == 1) and (h == 1):\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        self.driver.find_element_by_xpath(f'.//div[{i}]/div[{h}]/a/div[1]/div').click()\n",
    "                        sleep(1)\n",
    "                        valores = self.prepare()\n",
    "                        sleep(randint(1,3))\n",
    "                        result.append(valores)\n",
    "                    except:\n",
    "                        try:\n",
    "                            self.pruebita_matches()\n",
    "                        except:\n",
    "                            pass\n",
    "                    \n",
    "        self.back_to_swipe()\n",
    "    \n",
    "        return result\n",
    "\n",
    "    def messages_report(self):\n",
    "        \n",
    "        self.message_button()\n",
    "        number = self.get_number_of_messages()\n",
    "        result = []\n",
    "\n",
    "        for i in range(1, number+1):\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath(f'.//div[2]/a[{i}]/div[2]/div[1]').click()\n",
    "                sleep(1)\n",
    "                valores = self.prepare()\n",
    "                sleep(randint(1,3))\n",
    "                result.append(valores)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        self.back_to_swipe()\n",
    "            \n",
    "        return result\n",
    "                 \n",
    "    def match_report(self, links, name, age, location, distance, education, school, job, orientation, likes, s_likes, desc, p_len, spotify, artist, song, verif, sup_like, insta, tag):\n",
    "    \n",
    "        color = colors()\n",
    "        self.plot_images(links, tag)\n",
    "\n",
    "        #Número de fotos\n",
    "        print(f\"{color.BOLD}Fotos: {color.END}{p_len}\")\n",
    "        print()\n",
    "\n",
    "        #Nombre\n",
    "        print(f\"{color.BOLD}Nombre: {color.END}{name}\")\n",
    "        print()\n",
    "\n",
    "        #Edad\n",
    "        print(f\"{color.BOLD}Edad:{color.END} {age}\")\n",
    "        print()\n",
    "\n",
    "        #Info\n",
    "        print(f\"{color.BOLD}Location: {color.END}{location}\")\n",
    "        print(f\"{color.BOLD}Distance (km): {color.END}{distance}\")\n",
    "        print(f\"{color.BOLD}School: {color.END}{school}\")\n",
    "        print(f\"{color.BOLD}Job: {color.END}{job}\")\n",
    "        print(f\"{color.BOLD}Orientation: {color.END}{orientation}\")\n",
    "        print()\n",
    "\n",
    "        #Similar Likes\n",
    "        print(f\"{color.BOLD}Similar likes: {color.END} {s_likes}\")\n",
    "        print()\n",
    "\n",
    "        #Likes\n",
    "        print(f\"{color.BOLD}Likes: {color.END} {likes}\")\n",
    "        print()\n",
    "\n",
    "        #Descripición\n",
    "        print(f\"{color.BOLD}Descripción: {color.END}\")\n",
    "        print(desc)\n",
    "        print()\n",
    "\n",
    "        #Perfil verificado\n",
    "        print(f'{color.BOLD}Verified:{color.END} {verif}')\n",
    "        print()\n",
    "\n",
    "        #Super like\n",
    "        print(f'{color.BOLD}Super liked me:{color.END} {sup_like}')\n",
    "        print()\n",
    "\n",
    "        #Instagram\n",
    "        print(f'{color.BOLD}Instagram:{color.END} {insta}')\n",
    "        print()\n",
    "\n",
    "        #Spotify\n",
    "        print(f'{color.BOLD}Spotify:{color.END} {spotify}')\n",
    "        print(f'{color.BOLD}Artist:{color.END} {artist}')\n",
    "        print(f'{color.BOLD}Song:{color.END} {song}')\n",
    "        print()\n",
    "        print('---------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    def prepare(self):\n",
    "\n",
    "        #result = []\n",
    "        \n",
    "        self.info_button()\n",
    "        sleep(5)\n",
    "        \n",
    "        actions = ActionChains(self.driver)\n",
    "        sopa = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "        sleep(0.3)\n",
    "        \n",
    "        photo_len = self.get_photo_len(sopa)\n",
    "        sleep(0.5)\n",
    "        name = self.get_name(sopa)\n",
    "        sleep(0.1)\n",
    "        age = self.get_age(sopa)\n",
    "        sleep(0.1)\n",
    "        informacion = self.get_info(sopa)\n",
    "        sleep(0.7)\n",
    "\n",
    "        info = dict.fromkeys(['location', 'distance', 'education', 'school', 'job', 'orientation'], None)\n",
    "\n",
    "        for i in range(len(informacion)):\n",
    "            if 'Lives in' in informacion[i]:\n",
    "                info['location'] = informacion[i].replace('Lives in ','')\n",
    "            if 'kilometres away' in informacion[i]:\n",
    "                info['distance'] = informacion[i].replace('kilometres away','')\n",
    "            if education in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "                info['school'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "            if work in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "                info['job'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "            if gender in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "                info['orientation'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "\n",
    "        location = info['location']\n",
    "        distance = info['distance']\n",
    "        school = info['school']\n",
    "        job = info['job']\n",
    "        orientation = info['orientation']\n",
    "\n",
    "        description = self.get_description(sopa)\n",
    "        likes = self.get_likes(sopa)\n",
    "        similar_likes = self.get_similar_likes(sopa)\n",
    "        sleep(0.1)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H-%M-%S\")\n",
    "        id_tag = f\"{name[0]}-{age}_{current_time}\"\n",
    "\n",
    "        photo_links = self.scrap_photos(photo_len)\n",
    "        sleep(2)\n",
    "        self.save_images(photo_links, id_tag)\n",
    "        sleep(2)\n",
    "        \n",
    "        verif = self.verified(sopa)\n",
    "        sup_like = self.super_like(sopa)\n",
    "        insta = self.get_instagram(sopa)\n",
    "\n",
    "        music = dict.fromkeys(['spotify', 'artist', 'song'], False)\n",
    "\n",
    "        if self.get_spotify(sopa) == True:\n",
    "            music['spotify'] = True\n",
    "            music['artist'] = self.get_artist(sopa)\n",
    "            music['song'] = self.get_song(sopa)\n",
    "\n",
    "        spotify = music['spotify']\n",
    "        artist = music['artist']\n",
    "        song = music['song']\n",
    "\n",
    "        #self.match_report(photo_links, name, age, location, distance, education, school, job, orientation, likes, similar_likes, description, photo_len, spotify, artist, song, verif, sup_like, insta, id_tag)\n",
    "\n",
    "        #self.delete_images(id_tag)\n",
    "        self.info_out()\n",
    "\n",
    "        atr_score = None\n",
    "        desc_score =  None\n",
    "\n",
    "        return name, age, photo_len, school, job, orientation, location, distance, similar_likes, likes, description, verif, sup_like, insta, spotify, artist, song, atr_score, desc_score, id_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = TinderBot()\n",
    "bot.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows = bot.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['name','age', 'number_of_photos', 'education', 'work', 'sexual_orientation', 'location','km_distance','similar_likes','other_likes','description','verified','super_liked_me','instagram','spotify','artist','song', 'attractiveness_score', 'description_score', 'photos_folder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list([rows]), columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.get_number_of_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "531"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.get_number_of_matches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bot.messages_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_photos</th>\n",
       "      <th>education</th>\n",
       "      <th>work</th>\n",
       "      <th>sexual_orientation</th>\n",
       "      <th>location</th>\n",
       "      <th>km_distance</th>\n",
       "      <th>similar_likes</th>\n",
       "      <th>other_likes</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>super_liked_me</th>\n",
       "      <th>instagram</th>\n",
       "      <th>spotify</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>attractiveness_score</th>\n",
       "      <th>description_score</th>\n",
       "      <th>photos_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brenda</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Straight</td>\n",
       "      <td>Toluca de Lerdo</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>Running, Hiking, Sports, Outdoors, Wine</td>\n",
       "      <td>🇲🇽\\n1.60\\n@Brendarrdz</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>B-26_16-13-36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fernanda</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>Universidad Maya</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Toluca de Lerdo</td>\n",
       "      <td>50</td>\n",
       "      <td>None</td>\n",
       "      <td>Photography, Brunch, Films, Dog lover, Wine</td>\n",
       "      <td>IG: fernanda_perez</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F-23_16-14-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mizo</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>Picnicking, Photography, Karaoke, Gamer, Films</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M-26_16-15-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andrea</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>Corporación universitaria UNITEC</td>\n",
       "      <td>None</td>\n",
       "      <td>Demisexual Woman</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>Museum</td>\n",
       "      <td>Cooking, Walking, Volunteering, Board games</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A-23_16-15-57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abigail</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>Universidad Pedagógica Nacional</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>72</td>\n",
       "      <td>None</td>\n",
       "      <td>Travel, Dog lover, Netflix</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A-23_16-16-54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name age  number_of_photos                         education  work  \\\n",
       "0    Brenda  26                 6                              None  None   \n",
       "1  Fernanda  23                 7                  Universidad Maya  None   \n",
       "2      Mizo  26                 6                              None  None   \n",
       "3    Andrea  23                 9  Corporación universitaria UNITEC  None   \n",
       "4   Abigail  23                 4   Universidad Pedagógica Nacional  None   \n",
       "\n",
       "  sexual_orientation         location km_distance similar_likes  \\\n",
       "0           Straight  Toluca de Lerdo         50           None   \n",
       "1               None  Toluca de Lerdo         50           None   \n",
       "2               None             None         32           None   \n",
       "3   Demisexual Woman             None          5         Museum   \n",
       "4               None             None         72           None   \n",
       "\n",
       "                                      other_likes            description  \\\n",
       "0         Running, Hiking, Sports, Outdoors, Wine  🇲🇽\\n1.60\\n@Brendarrdz   \n",
       "1     Photography, Brunch, Films, Dog lover, Wine     IG: fernanda_perez   \n",
       "2  Picnicking, Photography, Karaoke, Gamer, Films                   None   \n",
       "3     Cooking, Walking, Volunteering, Board games                   None   \n",
       "4                      Travel, Dog lover, Netflix                   None   \n",
       "\n",
       "   verified  super_liked_me  instagram  spotify artist   song  \\\n",
       "0      True           False      False    False  False  False   \n",
       "1      True           False       True    False  False  False   \n",
       "2     False           False      False    False  False  False   \n",
       "3     False           False      False    False  False  False   \n",
       "4     False           False      False    False  False  False   \n",
       "\n",
       "  attractiveness_score description_score  photos_folder  \n",
       "0                 None              None  B-26_16-13-36  \n",
       "1                 None              None  F-23_16-14-21  \n",
       "2                 None              None  M-26_16-15-11  \n",
       "3                 None              None  A-23_16-15-57  \n",
       "4                 None              None  A-23_16-16-54  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(x, columns = cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('messages.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y = bot.matches_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(y, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>number_of_photos</th>\n",
       "      <th>education</th>\n",
       "      <th>work</th>\n",
       "      <th>sexual_orientation</th>\n",
       "      <th>location</th>\n",
       "      <th>km_distance</th>\n",
       "      <th>similar_likes</th>\n",
       "      <th>other_likes</th>\n",
       "      <th>description</th>\n",
       "      <th>verified</th>\n",
       "      <th>super_liked_me</th>\n",
       "      <th>instagram</th>\n",
       "      <th>spotify</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>attractiveness_score</th>\n",
       "      <th>description_score</th>\n",
       "      <th>photos_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alma</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Universidad De Los Mochis</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>42</td>\n",
       "      <td>Coffee, Coffee</td>\n",
       "      <td>Astrology, Reading, Comedy, Dancing</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>Give Me Love</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A-24_17-17-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jazz</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>Fes Aragon UNAM</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>Photography, Fashion, Art, Sports, Films</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>J-24_17-17-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fernanda</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Straight Woman</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>14</td>\n",
       "      <td>None</td>\n",
       "      <td>Swimming, Music, Cooking, Dancing</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F-26_17-18-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dulce</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>58</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\\n</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>I Lived</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>D-25_17-19-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laura</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "      <td>UNAM</td>\n",
       "      <td>None</td>\n",
       "      <td>Woman</td>\n",
       "      <td>None</td>\n",
       "      <td>26</td>\n",
       "      <td>None</td>\n",
       "      <td>Grab a drink, Language exchange, Environmental...</td>\n",
       "      <td>Abriendo mi círculo social, me late muchísimo ...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Delafe y las flores azules</td>\n",
       "      <td>Mar el poder del mar</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>L-26_17-19-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name age  number_of_photos                  education  work  \\\n",
       "0      Alma  24                 3  Universidad De Los Mochis  None   \n",
       "1      Jazz  24                 2            Fes Aragon UNAM  None   \n",
       "2  Fernanda  26                 6                       None  None   \n",
       "3     Dulce  25                 1                       None  None   \n",
       "4     Laura  26                 8                       UNAM  None   \n",
       "\n",
       "  sexual_orientation          location km_distance   similar_likes  \\\n",
       "0               None              None         42   Coffee, Coffee   \n",
       "1               None  Ciudad de México         11             None   \n",
       "2     Straight Woman  Ciudad de México         14             None   \n",
       "3               None  Ciudad de México         58             None   \n",
       "4              Woman              None         26             None   \n",
       "\n",
       "                                         other_likes  \\\n",
       "0                Astrology, Reading, Comedy, Dancing   \n",
       "1           Photography, Fashion, Art, Sports, Films   \n",
       "2                  Swimming, Music, Cooking, Dancing   \n",
       "3                                               None   \n",
       "4  Grab a drink, Language exchange, Environmental...   \n",
       "\n",
       "                                         description  verified  \\\n",
       "0                                               None     False   \n",
       "1                                               None      True   \n",
       "2                                               None     False   \n",
       "3                                                 \\n     False   \n",
       "4  Abriendo mi círculo social, me late muchísimo ...      True   \n",
       "\n",
       "   super_liked_me  instagram  spotify                      artist  \\\n",
       "0           False       True     True                  Ed Sheeran   \n",
       "1           False      False    False                       False   \n",
       "2           False      False    False                       False   \n",
       "3           False      False     True                 OneRepublic   \n",
       "4           False      False     True  Delafe y las flores azules   \n",
       "\n",
       "                   song attractiveness_score description_score  photos_folder  \n",
       "0          Give Me Love                 None              None  A-24_17-17-12  \n",
       "1                 False                 None              None  J-24_17-17-46  \n",
       "2                 False                 None              None  F-26_17-18-16  \n",
       "3               I Lived                 None              None  D-25_17-19-02  \n",
       "4  Mar el poder del mar                 None              None  L-26_17-19-26  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('matches.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.back_to_swipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_path = f\"{os.getcwd()}/images/messages\"\n",
    "matches_path = f\"{os.getcwd()}/images/matches\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNames(target):\n",
    "    files = []\n",
    "    file_count = 0\n",
    "    path = f\"{messages_path}/%s/\" % (target)\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f: #BF-001 has several images\n",
    "            if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('messages.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"files\"] = df.photos_folder.apply(getFileNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings['label'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rankings = rankings.explode('files')[['photos_folder', 'files', 'label']]\n",
    "rankings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_labels = [0, 1]\n",
    "\n",
    "def check_valid_label(filename):\n",
    "    try:\n",
    "        inp = int(input('What\\'s the score?'))\n",
    "        if inp not in valid_labels:\n",
    "            print(\"results: status must be one of %r.\" % valid_labels)\n",
    "            inp = check_valid_label(filename)\n",
    "        else:\n",
    "            print(f'Label saved for file: {filename}')\n",
    "    except:\n",
    "        print(\"results: status must be one of %r.\" % valid_labels)\n",
    "        inp = check_valid_label(filename)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "def create_labels(path, csv_name):\n",
    "\n",
    "    labels = []\n",
    "    folder = []\n",
    "    files = []\n",
    "\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                files.append(file)\n",
    "                folder.append(r.split('/')[-1])\n",
    "\n",
    "    folder_path = [f\"{messages_path}/{folder[i]}\" for i in range(len(folder))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        im = PIL.Image.open(f\"{folder_path[i]}/{files[i]}\")\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        \n",
    "        inp = check_valid_label(files[i])\n",
    "        labels.append(int(inp))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    data = {'files':files, 'label':labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f'{csv_name}.csv') \n",
    "\n",
    "    print(f'\\n{csv_name}.csv saved!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_labels(messages_path, 'messages_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_labels(matches_path, 'matches_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(bot.driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-secondary) C($c-secondary)\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-pink) C($c-pink)\"]')\n",
    "lista = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-secondary) C($c-secondary)\"]')\n",
    "if len(lista) > 0:\n",
    "    all_similar_likes = ', '.join([lista[i].text for i in range(len(lista))])\n",
    "    print(all_similar_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-pink) C($c-pink)\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
