{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import math\n",
    "import cv2\n",
    "import sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from time import sleep\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import randint\n",
    "from secrets import username, password\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import itertools\n",
    "from googletrans import Translator\n",
    "import emoji\n",
    "import flag\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import sys\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.image import extract_face_landmarks\n",
    "import itertools\n",
    "from sklearn import linear_model\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_seq_items = 1000\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = TinderBot()\n",
    "bot.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = bot.messages_report()\n",
    "matches = bot.matches_report()\n",
    "\n",
    "messages.to_csv('messages.csv')\n",
    "matches.to_csv('matches.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_path = f\"{os.getcwd()}/images/messages\"\n",
    "matches_path = f\"{os.getcwd()}/images/matches\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking if scraping was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileNames(target, source):\n",
    "    files = []\n",
    "    file_count = 0\n",
    "    path = f\"{source}/%s/\" % (target)\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f: \n",
    "            if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                files.append(file)\n",
    "    return files\n",
    "\n",
    "def check_missing_photos(df, source):\n",
    "    \n",
    "    df[\"files\"] = df.folder.apply(getFileNames, args=[source])\n",
    "    df['file_count'] = df['files'].str.len()\n",
    "    missing = sum(df['number_of_photos'] - df['file_count'])\n",
    "    \n",
    "    if missing == 0:\n",
    "        df = df.drop(columns=['file_count', 'files'], inplace = True)\n",
    "        print('All photos were scraped correctly!')\n",
    "    else:\n",
    "        print(f'{missing} photos are missing. There was a problem scraping photos in the following folders:\\n')\n",
    "        df['missing'] = df['number_of_photos'] - df['file_count']\n",
    "        print(df[(df['number_of_photos'] - df['file_count'] > 0) == True][['folder', 'missing']])\n",
    "\n",
    "        while True:\n",
    "            ans = ['y', 'n']    \n",
    "            inp = input('Do you want to continue working with you current photos? (y/n)')\n",
    "\n",
    "            if inp.lower() in ans:        \n",
    "                if inp == 'y':\n",
    "                    df['number_of_photos'] = df['file_count']\n",
    "                    df = df.drop(columns = ['file_count', 'files', 'missing'], inplace = True)\n",
    "                    print('Photo lenght succesfully modified')\n",
    "                    break\n",
    "                else:\n",
    "                    print('Scrap the remaining photos or decide what you want to do before continuing')\n",
    "                    break\n",
    "            else:\n",
    "                print('Please provide a valid answer (y/n)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_msgs = pd.read_csv('messages.csv')\n",
    "cols = ['name','age', 'number_of_photos', 'education', 'work', 'sexual_orientation', 'location','km_distance','similar_likes','other_likes','description','verified','super_liked_me','instagram','spotify','artist','song', 'attractiveness_score', 'description_score', 'folder']\n",
    "df_msgs.columns = cols\n",
    "df_msgs['messaged_me'] = 1\n",
    "df_msgs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_missing_photos(df_msgs, messages_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_mtchs = pd.read_csv('matches.csv')\n",
    "df_mtchs.columns = cols\n",
    "df_mtchs['messaged_me'] = 0\n",
    "df_mtchs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missing_photos(df_mtchs, matches_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check if face appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_num_face(tag):\n",
    "\n",
    "    files = []\n",
    "    face_images = []\n",
    "    face_files = []\n",
    "\n",
    "    for r, d, f in os.walk(f\"./images/matches/{tag}\"):\n",
    "        for file in f:\n",
    "            if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                files.append(f\"./images/matches/{tag}/{file}\")\n",
    "                \n",
    "    for i in range(len(files)):        \n",
    "        \n",
    "        imagePath = sys.argv[1]\n",
    "        cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "        faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "        photo = f\"{files[i]}\"\n",
    "\n",
    "        image = cv2.imread(photo)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        if int(len(faces)) == 1:\n",
    "            face_files.append(files[i])\n",
    "            face_images.append(mpimg.imread(f\"{files[i]}\"))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    data = {'files':face_files}\n",
    "    df = pd.DataFrame(data)\n",
    "    plt.figure(figsize=(20,10))\n",
    "    columns = len(face_images)\n",
    "    \n",
    "    for i, image in enumerate(face_images):\n",
    "        plt.subplot(int(len(face_images)/columns+1), columns, i+1)\n",
    "        plt.imshow(image)\n",
    "        plt.gca().axes.get_yaxis().set_visible(False)\n",
    "        plt.gca().axes.get_xaxis().set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_num_face(path, tag):\n",
    "\n",
    "    face_check = []\n",
    "    files = []\n",
    "\n",
    "    for r, d, f in os.walk(f\"{path}\"):\n",
    "        for file in f:\n",
    "            if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                files.append(file)\n",
    "\n",
    "    for i in range(len(files)):        \n",
    "        \n",
    "        imagePath = sys.argv[1]\n",
    "        cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "        faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "        photo = f\"{path}/{tag}/{files[i]}\"\n",
    "\n",
    "        image = cv2.imread(photo)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        \n",
    "        face_check.append(int(len(faces)))\n",
    "\n",
    "    data = {'files':files, 'face': face_check}\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#df_faces = pd.read_csv('df_faces.csv')\n",
    "faces_msg = create_num_face(messages_path)\n",
    "faces_msg = faces_msg[faces_msg['face'] == 1]\n",
    "\n",
    "faces_matches = create_num_face(matches_path)\n",
    "faces_matches = faces_matches[faces_matches['face'] == 1]\n",
    "\n",
    "df_faces = pd.concat([faces_msg, faces_matches])\n",
    "df_faces.to_csv('df_faces.csv')\n",
    "\n",
    "df_faces.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels = [0, 1, 2, 3, 4, 5]\n",
    "\n",
    "def check_valid_label(filename):\n",
    "    try:\n",
    "        inp = int(input('What\\'s the score?'))\n",
    "        if inp not in valid_labels:\n",
    "            print(\"results: status must be one of %r.\" % valid_labels)\n",
    "            inp = check_valid_label(filename)\n",
    "        else:\n",
    "            print(f'Label saved for file: {filename}')\n",
    "    except:\n",
    "        print(\"results: status must be one of %r.\" % valid_labels)\n",
    "        inp = check_valid_label(filename)\n",
    "    \n",
    "    return inp\n",
    "\n",
    "def create_face_labels(path, csv_name):\n",
    "\n",
    "    labels = []\n",
    "    folder = []\n",
    "    files = []\n",
    "\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file in list(df_faces['files']):\n",
    "                files.append(file)\n",
    "                folder.append(r.split('/')[-1])\n",
    "\n",
    "    folder_path = [f\"{path}/{folder[i]}\" for i in range(len(folder))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        im = PIL.Image.open(f\"{folder_path[i]}/{files[i]}\")\n",
    "        plt.imshow(im)\n",
    "        plt.show()\n",
    "        \n",
    "        inp = check_valid_label(files[i])\n",
    "        labels.append(int(inp))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    data = {'files':files, 'folder':folder, 'ratings':labels}\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f'{csv_name}.csv', index = False) \n",
    "\n",
    "    print(f'\\n{csv_name}.csv saved!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_face_ratings = create_face_labels(messages_path, 'message_face_ratings')\n",
    "msg_face_ratings['messaged_me'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msg_face_ratings = pd.read_csv('msg_face_ratings.csv')\n",
    "#msg_face_ratings.head()\n",
    "msg_face_ratings = pd.merge(pd.read_csv('message_face_labels.csv').drop(columns=['label']), pd.read_csv('message_labels.csv').set_index('folder'))\n",
    "msg_face_ratings.columns = ['files', 'folder', 'ratings']\n",
    "msg_face_ratings['messaged_me'] = 1\n",
    "msg_face_ratings.to_csv('msg_face_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matches_face_ratings = create_face_labels(matches_path, 'matches_face_ratings')\n",
    "matches_face_ratings['messaged_me'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matches_face_ratings = pd.read_csv('matches_face_ratings.csv')\n",
    "#matches_face_ratings.head()\n",
    "matches_face_ratings = pd.merge(pd.read_csv('matches_face_labels.csv').drop(columns=['label']), pd.read_csv('matches_labels.csv').set_index('folder'))\n",
    "matches_face_ratings.columns = ['files', 'folder', 'ratings']\n",
    "matches_face_ratings['messaged_me'] = 0\n",
    "matches_face_ratings.to_csv('matches_face_ratings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.concat([msg_face_ratings, matches_face_ratings])\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces(path):\n",
    "\n",
    "    folder = []\n",
    "    files = []\n",
    "\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file in list(df_faces['files']):\n",
    "                files.append(file)\n",
    "                folder.append(r.split('/')[-1])\n",
    "\n",
    "    folder_path = [f\"{path}/{folder[i]}\" for i in range(len(folder))]\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        imagePath = sys.argv[1]\n",
    "        cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "        faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "        image = cv2.imread(f\"{folder_path[i]}/{files[i]}\")\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        landmarks = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.2,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "    \n",
    "        for (x, y, w, h) in landmarks: \n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (0, 0, 255), 2) \n",
    "            landmarks = image[y:y + h, x:x + w] \n",
    "            lugar = f\"{os.getcwd()}/cropped_faces/\"\n",
    "            cv2.imwrite(os.path.join(lugar , f'{files[i]}'), landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_faces(messages_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_faces(matches_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering non-faces and resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{os.getcwd()}/cropped_faces/\"\n",
    "\n",
    "width = []\n",
    "heigth = []\n",
    "\n",
    "for i in range(len(train_df['files'])):\n",
    "    image = PIL.Image.open(f\"{path}{train_df['files'][i]}\")\n",
    "    w, h = image.size\n",
    "    width.append(w)\n",
    "    heigth.append(h)\n",
    "    \n",
    "avg_width = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filtering_non_faces(csv_name):\n",
    "\n",
    "    basewidth = 224\n",
    "    files = []\n",
    "    features = []\n",
    "    face_files = []\n",
    "\n",
    "    path = f\"{os.getcwd()}/cropped_faces/\"\n",
    "\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file in list(df_faces['files']):\n",
    "                files.append(f\"{file}\")\n",
    "\n",
    "    for i in range(len(files)):\n",
    "        img = imageio.imread(f\"{path}{files[i]}\")\n",
    "        landmarks = extract_face_landmarks(img)\n",
    "\n",
    "        if type(landmarks) == type(None):\n",
    "            os.remove(f\"{path}{files[i]}\")\n",
    "            pass\n",
    "        else:\n",
    "            features.append(landmarks)\n",
    "            face_files.append(files[i])\n",
    "            img = PIL.Image.open(f\"{path}{files[i]}\")\n",
    "            wpercent = (basewidth/float(img.size[0]))\n",
    "            hsize = int((float(img.size[1])*float(wpercent)))\n",
    "            img = img.resize((basewidth, hsize), PIL.Image.ANTIALIAS)\n",
    "            img.save(f\"{path}{files[i]}\")\n",
    "          \n",
    "    data = {'files':face_files, 'landmarks':features}\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f'{csv_name}.csv', index = False) \n",
    "\n",
    "    print(f'\\n{csv_name}.csv saved!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtered_faces = pd.read_csv('only_faces.csv')\n",
    "#filtered_faces.shape\n",
    "filtered_faces = filtering_non_faces('only_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = filtered_faces.merge(training, on=['files'], how='inner')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_msgs = pd.read_csv('messages.csv')\n",
    "#df_msgs.head(1)\n",
    "\n",
    "train_df[train_df['messaged_me'] == 1].groupby('folder', as_index=False).agg({'files':'count', 'ratings':'sum'})\n",
    "\n",
    "temp_df = df_msgs.merge(train_df[train_df['messaged_me'] == 1].groupby('folder', as_index=False).agg({'files':'count', 'ratings':'sum'}))\n",
    "temp_df['attractiveness_score'] = round(temp_df['ratings']/temp_df['files'],2)\n",
    "temp_df.drop(columns=['ratings', 'files'], inplace = True)\n",
    "temp_df = temp_df[['attractiveness_score', 'folder']]\n",
    "\n",
    "df_msgs = pd.merge(df_msgs, temp_df,  on ='folder', how ='left').drop(columns=['attractiveness_score_x']).rename(columns={\"attractiveness_score_y\": \"attractiveness_score\"})\n",
    "df_msgs.to_csv('messages.csv')\n",
    "df_msgs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mtchs = pd.read_csv('matches.csv')\n",
    "#df_mtchs.head(1)\n",
    "\n",
    "train_df[train_df['messaged_me'] == 0].groupby('folder', as_index=False).agg({'files':'count', 'ratings':'sum'})\n",
    "\n",
    "temp_df = df_mtchs.merge(train_df[train_df['messaged_me'] == 0].groupby('folder', as_index=False).agg({'files':'count', 'ratings':'sum'}))\n",
    "temp_df['attractiveness_score'] = round(temp_df['ratings']/temp_df['files'],2)\n",
    "temp_df.drop(columns=['ratings', 'files'], inplace = True)\n",
    "temp_df = temp_df[['attractiveness_score', 'folder']]\n",
    "\n",
    "df_mtchs = pd.merge(df_mtchs, temp_df,  on ='folder', how ='left').drop(columns=['attractiveness_score_x']).rename(columns={\"attractiveness_score_y\": \"attractiveness_score\"})\n",
    "df_mtchs.to_csv('matches.csv')\n",
    "df_mtchs.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrievePixels(path):\n",
    "    img = image.load_img(path, grayscale=False, target_size=(224, 224)) \n",
    "    x = image.img_to_array(img).reshape(1, -1)[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrievePixels(path):\n",
    "    img = image.load_img(path, grayscale=False, target_size=(224, 224)) \n",
    "    x = image.img_to_array(img).reshape(1, -1)[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_deep = train_df.copy()\n",
    "df_deep['f_path'] = f'{os.getcwd()}/cropped_faces/' + df_deep['files']\n",
    "df_deep['pixels'] = df_deep['f_path'].progress_apply(retrievePixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, instance in df_deep.sort_values(by=['ratings'], ascending = False).head(3).iterrows():\n",
    "    img = instance.pixels\n",
    "    img = img.reshape(224, 224, 3)\n",
    "    img = img / 255\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    print(instance.files)\n",
    "    print(\"Attractiveness score: \", instance.ratings)\n",
    "    \n",
    "    print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "pixels = df_deep['pixels'].values\n",
    "for i in range(0, pixels.shape[0]):\n",
    "    features.append(pixels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, df_deep.ratings.values, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set: \", X_train.shape[0])\n",
    "print(\"Test set: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Sequential()\n",
    "base_model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "base_model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(ZeroPadding2D((1,1)))\n",
    "base_model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "base_model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "base_model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "base_model.add(Dropout(0.5))\n",
    "base_model.add(Convolution2D(2622, (1, 1)))\n",
    "base_model.add(Flatten())\n",
    "base_model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights('./data/vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ratings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Flatten()(base_model.layers[-4].output)\n",
    "base_model_output = Dense(num_of_classes)(base_model_output)\n",
    "\n",
    "attractiveness_model = Model(inputs=base_model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractiveness_model.compile(loss='mean_squared_error', optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='%s.hdf5' % (target)\n",
    "    , monitor = \"val_loss\"\n",
    "    , verbose=1\n",
    "    , save_best_only=True\n",
    "    , mode = 'auto'\n",
    ")\n",
    "\n",
    "earlyStop = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = attractiveness_model.fit(\n",
    "    X_train, y_train\n",
    "    , epochs=5000\n",
    "    , validation_data=(X_test, y_test)\n",
    "    , callbacks=[checkpointer, earlyStop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_iteration = np.argmin(score.history['val_loss'])+1\n",
    "\n",
    "test_scores = score.history['val_loss'][0:best_iteration]\n",
    "train_scores = score.history['loss'][0:best_iteration]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_scores, label='val_loss')\n",
    "plt.plot(train_scores, label='train_loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attractiveness_model = load_model(\"%s.hdf5\" % (target))\n",
    "attractiveness_model.save_weights('%s.h5' % (target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = attractiveness_model.predict(X_test)\n",
    "actuals = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf = pd.DataFrame(actuals, columns = [\"actuals\"])\n",
    "perf[\"predictions\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pearson correlation: \",perf[['actuals', 'predictions']].corr(method ='pearson').values[0,1])\n",
    "print(\"mae: \", mean_absolute_error(actuals, predictions))\n",
    "print(\"rmse: \", sqrt(mean_squared_error(actuals, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_limit = df_deep.ratings.min(); max_limit = df_deep.ratings.max()\n",
    "best_predictions = []\n",
    "\n",
    "#for i in np.arange(1, 7, 0.01):\n",
    "for i in np.arange(int(min_limit), int(max_limit)+1, 0.01):\n",
    "    best_predictions.append(round(i, 2))\n",
    "\n",
    "plt.scatter(best_predictions, best_predictions, s=1, color = 'black', alpha=0.5)\n",
    "plt.scatter(predictions, actuals, s=20, alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import _pickle as pickle\n",
    "from nltk import FreqDist\n",
    "import plotly.io as pio\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "\n",
    "from googletrans import Translator\n",
    "from google_trans_new import google_translator\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "import emoji\n",
    "import flag\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(service_urls=['translate.googleapis.com'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msgs['description'] = df_msgs['description'].apply(lambda x: np.nan if type(x) == float else x.replace('\\n',' ').replace('\\r','').replace(',', ' ').replace('.', ' ').replace(':', ' '))\n",
    "df_msgs['description'] = df_msgs['description'].apply(lambda x: np.nan if type(x) == float else translator.translate(x).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mtchs['description'] = df_mtchs['description'].apply(lambda x: np.nan if type(x) == float else x.replace('\\n','').replace(',', '').replace('.', ' ').replace(':', ' '))\n",
    "df_mtchs['description'] = df_mtchs['description'].apply(lambda x: np.nan if type(x) == float else translator.translate(x).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def is_flag_emoji(c):\n",
    "    return \"\\U0001F1E6\\U0001F1E8\" <= c <= \"\\U0001F1FF\\U0001F1FC\" or c in [\"\\U0001F3F4\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f\", \"\\U0001F3F4\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f\", \"\\U0001F3F4\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f\"]\n",
    "\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  \n",
    "        u\"\\U0001F680-\\U0001F6FF\"  \n",
    "        u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def give_emoji_free_text(text):\n",
    "    allchars = [str for str in text]\n",
    "    emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI['en']]\n",
    "    clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "    return clean_text\n",
    "\n",
    "def tokenization(text):    \n",
    "    try:\n",
    "        token = []\n",
    "        stops = stopwords.words('english')\n",
    "        \n",
    "        emojis = list(set([c for c in text if c in emoji.UNICODE_EMOJI['en']]))\n",
    "        flag_emojis = [c for c in text if is_flag_emoji(c) == True]\n",
    "        flags = list(set([i+j for i,j in zip(flag_emojis[::2], flag_emojis[1::2])]))\n",
    "        not_text = emojis + flags\n",
    "        \n",
    "        text = deEmojify(text)\n",
    "        clean_text = give_emoji_free_text(text).replace(',', '').replace('.', '').replace(':','').lower().split()\n",
    "\n",
    "        for i in clean_text:\n",
    "            word, tag = pos_tag(word_tokenize(i))[0]\n",
    "            wntag = tag[0].lower()\n",
    "            wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "            \n",
    "            if not wntag:\n",
    "                lemma = word\n",
    "                if lemma not in stops:\n",
    "                    token.append(lemma) \n",
    "            else:\n",
    "                lemma = lemmatizer.lemmatize(word, wntag)\n",
    "                if lemma not in stops:\n",
    "                    token.append(lemma)\n",
    "                            \n",
    "        return list(set(token))+emojis+flags\n",
    "    \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_msgs = pd.read_csv('messages_tokenized.csv')\n",
    "#df_mtchs = pd.read_csv('matches_tokenized.csv')\n",
    "\n",
    "df_msgs['tokenized'] = df_msgs['description'].apply(lambda x: np.nan if type(x) == float else tokenization(x))\n",
    "df_mtchs['tokenized'] = df_mtchs['description'].apply(lambda x: np.nan if type(x) == float else tokenization(x))\n",
    "\n",
    "df_msgs.to_csv('messages_tokenized.csv')\n",
    "df_mtchs.to_csv('matches_tokenized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_msgs, df_mtchs])\n",
    "df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_vocab = set()\n",
    "\n",
    "for bio in df['tokenized']:\n",
    "    try:\n",
    "        res = bio.replace(\"'\",\"\").strip('][').split(', ')\n",
    "        total_vocab.update(res)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"Number of unique words: \",len(total_vocab))\n",
    "\n",
    "words = []\n",
    "\n",
    "for bio in df['tokenized']:\n",
    "    try:\n",
    "        res = bio.replace(\"'\",\"\").strip('][').split(', ')\n",
    "        words.extend(res)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "bio_freq = FreqDist(words)\n",
    "bio_freq.most_common(509)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.bar(*zip(*bio_freq.most_common(10)))\n",
    "plt.xticks(rotation=75)\n",
    "plt.title('Top 10 Most Frequently Used Words in my Tinder Matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_meas = BigramAssocMeasures()\n",
    "bio_finder = BigramCollocationFinder.from_words(words)\n",
    "bio_scored = bio_finder.score_ngrams(bigram_meas.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg = list(map(lambda x: x[0][0] + '_' + x[0][1], bio_scored[:10]))\n",
    "bio_scores = list(map(lambda x: x[1], bio_scored[:10]))\n",
    "bigrams = list(zip(bg, bio_scores))\n",
    "\n",
    "plt.style.use('bmh')\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(*zip(*bigrams[:10]))\n",
    "plt.xticks(rotation=80)\n",
    "plt.title('Top 10 Bigramas más comúnes en mis matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.bar(bigrams, x=bg, y=bio_scores, height=400, labels=dict(x=\"Bigrams\", y=\"%\"))\n",
    "fig.update_traces(marker_color='green')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig, 'bigrams.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_finder.apply_freq_filter(20)\n",
    "bio_pmi = bio_finder.score_ngrams(bigram_meas.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_pmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msgs.description.apply(lambda bio: np.nan if type(bio) == float else BigramCollocationFinder.from_words(bio).nbest(bigram_meas.pmi, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join([(k + \" \")*v for k,v in bio_freq.items()])\n",
    "\n",
    "wordcloud = WordCloud(collocations=False, max_font_size=40).generate(text)\n",
    "\n",
    "fig = plt.figure(figsize = (20, 10), facecolor = 'k', edgecolor = 'k')\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    vec1 = Counter(a)\n",
    "    vec2 = Counter(b)\n",
    "    \n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "def get_result(content_a, content_b):\n",
    "    text1 = content_a\n",
    "    text2 = content_b\n",
    "\n",
    "    vector1 = text_to_vector(text1)\n",
    "    vector2 = text_to_vector(text2)\n",
    "\n",
    "    cosine_result = get_cosine(vector1, vector2)\n",
    "    return cosine_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
