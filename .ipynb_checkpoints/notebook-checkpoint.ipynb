{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.collocations import BigramAssocMeasures, BigramCollocationFinder\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import Image, display, clear_output\n",
    "from mlxtend.image import extract_face_landmarks\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import pathlib\n",
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import math\n",
    "import cv2\n",
    "import sys\n",
    "import imageio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from time import sleep\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from random import randint\n",
    "from secrets import username, password\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import itertools\n",
    "from googletrans import Translator\n",
    "import emoji\n",
    "import flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_seq_items = 1000\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"5\"\n",
    "\n",
    "work = 'M7.15 3.434h5.7V1.452a.728.728 0 0 0-.724-.732H7.874a.737.737 0 0 0-.725.732v1.982z'\n",
    "education = 'M11.87 5.026L2.186 9.242c-.25.116-.25.589 0 .705l.474.204v2.622a.78.78 0 0 0-.344.657c0 .42.313.767.69.767.378 0 .692-.348.692-.767a.78.78 0 0 0-.345-.657v-2.322l2.097.921a.42.42 0 0 0-.022.144v3.83c0 .45.27.801.626 1.101.358.302.842.572 1.428.804 1.172.46 2.755.776 4.516.776 1.763 0 3.346-.317 4.518-.777.586-.23 1.07-.501 1.428-.803.355-.3.626-.65.626-1.1v-3.83a.456.456 0 0 0-.022-.145l3.264-1.425c.25-.116.25-.59 0-.705L12.13 5.025c-.082-.046-.22-.017-.26 0v.001zm.13.767l8.743 3.804L12 13.392 3.257 9.599l8.742-3.806zm-5.88 5.865l5.75 2.502a.319.319 0 0 0 .26 0l5.75-2.502v3.687c0 .077-.087.262-.358.491-.372.29-.788.52-1.232.68-1.078.426-2.604.743-4.29.743s-3.212-.317-4.29-.742c-.444-.161-.86-.39-1.232-.68-.273-.23-.358-.415-.358-.492v-3.687z'\n",
    "gender = 'M15.507 13.032c1.14-.952 1.862-2.656 1.862-5.592C17.37 4.436 14.9 2 11.855 2 8.81 2 6.34 4.436 6.34 7.44c0 3.07.786 4.8 2.02 5.726-2.586 1.768-5.054 4.62-4.18 6.204 1.88 3.406 14.28 3.606 15.726 0 .686-1.71-1.828-4.608-4.4-6.338'\n",
    "cols = ['name','age', 'number_of_photos', 'education', 'work', 'sexual_orientation', 'location','km_distance','similar_likes','other_likes','description','verified','super_liked_me','instagram','spotify','artist','song', 'attractiveness_score', 'description_score', 'folder']\n",
    "\n",
    "#My model\n",
    "attractiveness_model = load_model(\"ratings.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class colors():\n",
    "    \n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "class TinderBot():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.options = webdriver.ChromeOptions()\n",
    "        self.options.add_argument('--incognito')\n",
    "        self.options.add_argument(\"--disable-infobars\")\n",
    "        self.options.add_argument(\"start-maximized\")\n",
    "        self.options.add_argument(\"--disable-extensions\")\n",
    "        self.options.add_argument(\"--disable-popup-blocking\")\n",
    "\n",
    "        prefs = {\n",
    "            'profile.default_content_setting_values':\n",
    "            {\n",
    "                'notifications': 1,\n",
    "                'geolocation': 1\n",
    "            },\n",
    "\n",
    "            'profile.managed_default_content_settings':\n",
    "            {\n",
    "                'geolocation': 1\n",
    "            },\n",
    "        }\n",
    "\n",
    "        self.options.add_experimental_option('prefs', prefs)\n",
    "        self.driver = webdriver.Chrome('/Applications/Avid/Licenses/Licence/Data_Science/Ironhack/Data_Analytics/chromedriver', options=self.options)\n",
    "    \n",
    "    def login(self):\n",
    "        self.driver.get('https://tinder.com')\n",
    "\n",
    "        assert \"Tinder\" in self.driver.title\n",
    "\n",
    "        sleep(randint(1,5))\n",
    "        log_in = self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div/div/header/div/div[2]/div[2]/button')\n",
    "        log_in.click()\n",
    "\n",
    "        sleep(randint(1,5))\n",
    "\n",
    "        self.driver.switch_to_alert\n",
    "\n",
    "        sleep(randint(1,5))\n",
    "\n",
    "        fb_button = self.driver.find_element_by_xpath('.//div/div/div[1]/div/div[3]/span/div[2]/button/span[2]')\n",
    "        fb_button.click()\n",
    "\n",
    "        window_before = self.driver.window_handles[0]\n",
    "        window_after = self.driver.window_handles[1]\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        self.driver.switch_to.window(window_after)\n",
    "\n",
    "        user_in = self.driver.find_element_by_xpath('//*[@id=\"email\"]')\n",
    "        user_in.send_keys(username)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        pass_in = self.driver.find_element_by_xpath('//*[@id=\"pass\"]')\n",
    "        pass_in.send_keys(password)\n",
    "\n",
    "        login_btn = self.driver.find_element_by_xpath('/html/body/div/div[2]/div[1]/form/div/div[3]/label[2]/input')\n",
    "        login_btn.click()\n",
    "\n",
    "        self.driver.switch_to.window(window_before)\n",
    "\n",
    "        sleep(5)\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div/div/div/div[3]/button[1]/span').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('/html/body/div[2]/div/div/div/div/div[3]/button[1]').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sleep(1.2)\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div/div/div/div[3]/button[1]').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('//*[@id=\"t--1610880557\"]/div/div/div/div/div[3]/button[1]').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        sleep(1.6)\n",
    "\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[2]/div/div/div[1]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('/html/body/div[1]/div/div[2]/div/div/div[1]/button').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def info_button(self):\n",
    "        \n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[1]/div[3]/div[3]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                WebDriverWait(self.driver, 4).until(EC.element_to_be_clickable((By.XPATH, \"/html/body/div[1]/div/div[1]/div/div/main/div/div[1]/div/div[1]/div[3]/div[3]/button\"))).click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_xpath(\"//div[contains(.,'Open Profile')]\").click()\n",
    "                except:\n",
    "                    try:\n",
    "                        self.driver.find_element_by_xpath(\"//div[contains(.,'Open Profile')]\").click()\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "    def to_photo(self):\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, './/div/div[1]/div/main/div[1]/div/div/div[1]'\n",
    "    ))).click()\n",
    "        except:\n",
    "            try:\n",
    "                WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]'))).click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def to_main(self):\n",
    "        \n",
    "        try:\n",
    "            WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, './/div/div[1]/div/main'))).click()\n",
    "        except:\n",
    "            try:\n",
    "                WebDriverWait(self.driver,4).until(EC.element_to_be_clickable((By.XPATH, '/html/body/div[1]/div/div[1]/div/main'))).click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_xpath(\".//div/div[1]/div/main\").click()\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    def back_to_swipe(self):\n",
    "        \n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div/div[1]/div/div/div[1]/a/button').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def get_name(self, soup):\n",
    "        \n",
    "        try:\n",
    "            name = soup.h1.string\n",
    "            return name\n",
    "        except:\n",
    "            try:\n",
    "                name = soup.find(\"span\", itemprop=\"name\").text\n",
    "                return name\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    def get_age(self, soup):\n",
    "        \n",
    "        try:\n",
    "            age = soup.select('div [class=\"Whs(nw) Fz($l)\"]')[0].text\n",
    "            return age\n",
    "        except:\n",
    "            try:\n",
    "                age = soup.find(\"span\", itemprop=\"age\").text\n",
    "                return age\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "    def get_info(self, soup):\n",
    "        \n",
    "        try:\n",
    "            info = soup.select('div [class=\"Row\"]')\n",
    "            all_info = [info[i].text for i in range(len(info))]\n",
    "            return all_info\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def get_description(self, soup):\n",
    "        \n",
    "        try:\n",
    "            description = soup.select('div [class=\"P(16px) Ta(start) Us(t) C($c-secondary) BreakWord Whs(pl) Fz($ms)\"]')[0].text\n",
    "            return description\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def get_likes(self, soup):\n",
    "        \n",
    "        try:\n",
    "            lista = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-secondary) C($c-secondary)\"]')\n",
    "            if len(lista) > 0:\n",
    "                all_likes = ', '.join([lista[i].text.strip().lower() for i in range(len(lista))])\n",
    "                return all_likes\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            pass           \n",
    "        \n",
    "    def get_similar_likes(self, soup):\n",
    "        \n",
    "        try:\n",
    "            lista = soup.select('div [class=\"Bdrs(100px) Bd D(ib) Fz($xs) Px(8px) Py(4px) Mend(4px) Mend(8px) Mb(8px) Mb(4px)--s Bdc($c-pink) C($c-pink)\"]')\n",
    "            if len(lista) > 0:\n",
    "                all_similar_likes = ', '.join([lista[i].text.strip().lower() for i in range(len(lista))])\n",
    "                return all_similar_likes\n",
    "            else:\n",
    "                return None\n",
    "        except:\n",
    "            pass   \n",
    "\n",
    "    def get_photo_len(self, soup):\n",
    "        \n",
    "        try:\n",
    "            photo_len = [int(i.text.strip()[-1]) for i in soup.select('div[class=\"CenterAlign D(f) Fxd(r) W(100%) Px(8px) Pos(a) TranslateZ(0)\"]')][0]\n",
    "            return photo_len\n",
    "        except:\n",
    "            return 1\n",
    "\n",
    "    def scrap_photos(self, photo_len):\n",
    "\n",
    "        links = []\n",
    "\n",
    "        for i in range(photo_len):\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath(f'.//div/div[1]/div/main/div[1]/div/div/div/div[2]/div/div[1]/div/div/div[1]/span/div/div[2]/button[{i+1}]').click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_xpath(f'/html/body/div[1]/div/div[1]/div/main/div[1]/div/div/div[1]/div[1]/div/div[1]/span/div/div[2]/button[{i+1}]').click()\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            sleep(2.5)\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "            sleep(0.5)\n",
    "            photos = soup.select('div[class=\"profileCard__slider__img Z(-1)\"]')\n",
    "            sleep(0.1)\n",
    "            sub_links = [str(photos[i]).split('(\"', 1)[1].split('\")')[0] for i in range(len(photos))]\n",
    "            links.append(sub_links)\n",
    "\n",
    "        flat_list = list(set([item for sublist in links for item in sublist]))\n",
    "        return flat_list\n",
    "\n",
    "    def save_images(self, number, tag):\n",
    "        \n",
    "        path = f'{os.getcwd()}/images/matches/{tag}'\n",
    "        os.mkdir(path)\n",
    "        \n",
    "        for i, url in enumerate(number):\n",
    "\n",
    "            save_webp = f'{path}/{i}-{tag}.webp'\n",
    "            save_jpg = f'{path}/{i}-{tag}.jpg'\n",
    "\n",
    "            if re.findall(r'([^.]*)$', url)[0] == 'webp':\n",
    "                PIL.Image.open(f'{urllib.request.urlretrieve(url, save_webp)[0]}').convert(\"RGB\").save(save_jpg,\"jpeg\")\n",
    "                sleep(0.5)\n",
    "                os.remove(save_webp)\n",
    "            else:\n",
    "                urllib.request.urlretrieve(url, save_jpg)\n",
    "\n",
    "    def get_spotify(self, soup):\n",
    "        \n",
    "        try:\n",
    "            h2_list = [i.text.strip().lower() for i in soup.select('div [class=\"P(16px)\"] > h2')]\n",
    "            if 'my anthem' in h2_list:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def get_artist(self, soup):\n",
    "        \n",
    "        artist = soup.select('div [class=\"D(f) Fz($s) C($c-secondary)\"]')[0].text\n",
    "        return artist\n",
    "\n",
    "    def get_song(self, soup):\n",
    "        \n",
    "        song = soup.select('div [class=\"Mb(4px) Ell Fz($ms)\"]')[0].text\n",
    "        return song\n",
    "\n",
    "    def get_instagram(self, soup):\n",
    "        \n",
    "        try:\n",
    "            h2_list = [i.text.strip().lower() for i in soup.select('div [class=\"P(16px)\"] > h2')]\n",
    "            if 'recent instagram photos' in h2_list:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "    def plot_images(self, number, tag):\n",
    "        \n",
    "        images = []\n",
    "        path = f'{os.getcwd()}/images/matches/{tag}'\n",
    "\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for img_path in files:\n",
    "                if img_path.endswith('.jpg'):\n",
    "                    images.append(mpimg.imread(f'{path}/{img_path}'))\n",
    "\n",
    "        plt.figure(figsize=(10,5))\n",
    "        columns = number\n",
    "\n",
    "        for i, image in enumerate(images):\n",
    "            plt.subplot(int(len(images)/columns+1), columns, i+1)\n",
    "            plt.imshow(image)\n",
    "            plt.gca().axes.get_yaxis().set_visible(False)\n",
    "            plt.gca().axes.get_xaxis().set_visible(False)\n",
    "        plt.show()\n",
    "     \n",
    "    def verified(self, soup):\n",
    "        \n",
    "        try:\n",
    "            icons = soup.select('div [class=\"D(ib) Lh(0) Sq(30px) Mstart(4px) As(c)\"]')\n",
    "            if len(icons) > 0:\n",
    "                for i in range(len(icons)):\n",
    "                    if 'Verified!' in icons[i].text:\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def super_like(self, soup):\n",
    "        try:\n",
    "            icons = soup.select('div [class=\"D(ib) Lh(0) Sq(30px) Mstart(4px) As(c)\"]')\n",
    "            if len(icons) > 0:\n",
    "                for i in range(len(icons)):\n",
    "                    if 'Super Like' in icons[i].text:\n",
    "                        return True\n",
    "                    else:\n",
    "                        return False\n",
    "            else:\n",
    "                return False\n",
    "        except:\n",
    "            pass          \n",
    "\n",
    "    def delete_images(self, tag):\n",
    "        \n",
    "        path = f'{os.getcwd()}/images/{tag}'\n",
    "        os.rmdir(path)\n",
    "\n",
    "    def info_out(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//a[@class=\"End(12px) B(-20px) Pos(a) Z(2) CenterAlign Bdrs(50%) P(0) Scale(1.1):h Trsdu($normal) focus-button-style\"]/*[name()=\"svg\"]/*[name()=\"g\"]').click()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def like_button(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(\".//div/div[1]/div/main/div[1]/div/div/div[1]/div[2]/div/div/div[4]/button\").click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[4]/button').click()\n",
    "            except:\n",
    "                try:\n",
    "                    self.driver.find_element_by_css_selector('#t--1032254752 > div > div.App__body.H\\(100\\%\\).Pos\\(r\\).Z\\(0\\) > div > div > main > div > div.recsCardboard.W\\(100\\%\\).Mt\\(a\\).H\\(100\\%\\)--s.Px\\(4px\\)--s.Pos\\(r\\) > div > div.Pos\\(r\\).Py\\(16px\\).Py\\(12px\\)--s.Px\\(4px\\).Px\\(8px\\)--ml.D\\(f\\).Jc\\(sb\\).Ai\\(c\\).Maw\\(375px\\)--m.Mx\\(a\\).Pe\\(n\\).Mt\\(-1px\\) > div:nth-child(4) > button > span > svg').click()\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    def dislike_button(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div[2]/div/div/div[2]/button').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/main/div[1]/div/div/div[1]/div/div[2]/div[2]/button').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def close_match(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('//*[@title=\"Back to Tinder\"]').click()\n",
    "        except:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div/div[1]/div/div[4]/button').click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def no_super_like(self):\n",
    "        try:\n",
    "            self.driver.find_element_by_xpath(\"/html/body/div[2]/div/div/button[2]\").click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def matches_button(self):\n",
    "        try:\n",
    "            mtchs_btn = self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav/div/div/div/div[1]/div/div[1]')\n",
    "            mtchs_btn.click()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def get_number_of_matches(self):\n",
    "        \n",
    "        self.matches_button()\n",
    "        \n",
    "        actions = ActionChains(self.driver)\n",
    "        m = 0 \n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div[1]/div[2]/a/div[1]/div').click()\n",
    "                sleep(2)\n",
    "                self.driver.find_element_by_xpath('.//div[1]/div[2]/a/div[1]/div').click()\n",
    "                sleep(2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            actions.send_keys(Keys.END)\n",
    "            actions.perform()\n",
    "            sleep(2)\n",
    "\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "            sleep(5)\n",
    "            number_of_matches = len(soup.select('div [class=\"P(8px)\"]'))\n",
    "\n",
    "            if (number_of_matches != m):\n",
    "                m = number_of_matches\n",
    "            else:\n",
    "                return number_of_matches\n",
    "                break\n",
    "                \n",
    "        self.back_to_swipe()\n",
    "          \n",
    "    def message_button(self):\n",
    "        try:\n",
    "            msg_btn = self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav/div/div/div/div[1]/div/div[2]')\n",
    "            msg_btn.click()\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "    def get_number_of_messages(self):\n",
    "    \n",
    "        self.message_button()\n",
    "        \n",
    "        actions = ActionChains(self.driver)\n",
    "        m = 0 \n",
    "\n",
    "        while True:\n",
    "            \n",
    "            try:\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav').click()\n",
    "                sleep(0.5)\n",
    "                self.driver.find_element_by_xpath('.//div/div[1]/div/aside/nav').click()\n",
    "                sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            actions.send_keys(Keys.END)\n",
    "            actions.perform()\n",
    "            sleep(1)\n",
    "\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "            sleep(1)\n",
    "            number_of_messages = len(soup.select('div [class=\"D(f) Fx($flx1) Ov(h) Fxd(c) Pend(10px)\"]'))\n",
    "\n",
    "            if (number_of_messages != m):\n",
    "                m = number_of_messages\n",
    "            else:\n",
    "                return number_of_messages\n",
    "                break\n",
    "                \n",
    "        self.back_to_swipe()\n",
    "               \n",
    "    def matches_report(self):\n",
    "        \n",
    "        self.matches_button()\n",
    "        number = self.get_number_of_matches()\n",
    "        result = []\n",
    " \n",
    "        for i in range (1, math.ceil(number/9)+1):\n",
    "            for h in range(1, 10):\n",
    "                if (i == 1) and (h == 1):\n",
    "                    pass\n",
    "                else:\n",
    "                    try:\n",
    "                        self.driver.find_element_by_xpath(f'.//div[{i}]/div[{h}]/a/div[1]/div').click()\n",
    "                        sleep(1)\n",
    "                        valores = self.prepare()\n",
    "                        sleep(randint(1,3))\n",
    "                        result.append(valores)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "        self.back_to_swipe()\n",
    "    \n",
    "        return result\n",
    "\n",
    "    def messages_report(self):\n",
    "        \n",
    "        self.message_button()\n",
    "        number = self.get_number_of_messages()\n",
    "        result = []\n",
    "\n",
    "        for i in range(1, number+1):\n",
    "            try:\n",
    "                self.driver.find_element_by_xpath(f'.//div[2]/a[{i}]/div[2]/div[1]').click()\n",
    "                sleep(1)\n",
    "                valores = self.prepare()\n",
    "                sleep(randint(1,3))\n",
    "                result.append(valores)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        self.back_to_swipe()\n",
    "            \n",
    "        return result\n",
    "\n",
    "    def get_my_bio(self):\n",
    "        \n",
    "        try:\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/aside/div/a/h2').click()\n",
    "            sleep(3.1)\n",
    "            my_bio = self.get_description(BeautifulSoup(self.driver.page_source, 'lxml'))\n",
    "            sleep(3.1)\n",
    "            self.driver.find_element_by_xpath('.//div/div[1]/div/aside/div/div/a').click()\n",
    "            return my_bio\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def check_missing_photos(self, photo_len, tag):\n",
    "        \n",
    "        path, dirs, files = next(os.walk(f\"./images/matches/{tag}\"))\n",
    "        file_count = len(files)\n",
    "        \n",
    "        missing = photo_len - file_count\n",
    "\n",
    "        if missing == 0:\n",
    "            print('All photos were scraped correctly!')\n",
    "            return file_count\n",
    "        else:\n",
    "            print(f'{missing} photos are missing')\n",
    "            return file_count\n",
    "        \n",
    "    \n",
    "    def create_num_face(self, tag):\n",
    "        \n",
    "        files = []\n",
    "        face_images = []\n",
    "        face_files = []\n",
    "\n",
    "        for r, d, f in os.walk(f\"./images/matches/{tag}\"):\n",
    "            for file in f:\n",
    "                if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                    files.append(f\"./images/matches/{tag}/{file}\")\n",
    "\n",
    "        for i in range(len(files)):        \n",
    "\n",
    "            imagePath = sys.argv[1]\n",
    "            cascPath = \"haarcascade_frontalface_default.xml\"\n",
    "            faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "            photo = f\"{files[i]}\"\n",
    "\n",
    "            image = cv2.imread(photo)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            faces = faceCascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.2,\n",
    "                minNeighbors=5,\n",
    "                minSize=(30, 30)\n",
    "            )\n",
    "            \n",
    "            basewidth = 224\n",
    "\n",
    "            if int(len(faces)) == 1:\n",
    "                face_files.append(files[i])\n",
    "                for (x, y, w, h) in faces: \n",
    "                    landmarks = image[y:y + h, x:x + w]\n",
    "                    \n",
    "                    height, width, channels = landmarks.shape\n",
    "                    wpercent = (basewidth/float(width))\n",
    "                    hsize = int((float(height)*float(wpercent)))\n",
    "                    \n",
    "                    output = cv2.resize(landmarks, (basewidth, hsize), fx=0.5, fy=0.5, interpolation = cv2.INTER_AREA)\n",
    "                    cv2.imwrite(f'{files[i]}',output) \n",
    "                    \n",
    "            else:\n",
    "                os.remove(files[i])\n",
    "\n",
    "        return len(face_files)\n",
    "    \n",
    "    def attractiveness_score(self, tag):\n",
    "\n",
    "        files = []\n",
    "        for r, d, f in os.walk(f\"./images/matches/{tag}\"):\n",
    "            for file in f:\n",
    "                if ('.jpg' in file) or ('.jpeg' in file) or '.png' in file:\n",
    "                    files.append(f\"./images/matches/{tag}/{file}\")\n",
    "                    \n",
    "        pixels = []\n",
    "        for i in files:                    \n",
    "            img = image.load_img(i, grayscale=False, target_size=(224, 224)) \n",
    "            x = image.img_to_array(img).reshape(1, -1)[0]\n",
    "            pixels.append(x)\n",
    "\n",
    "        features = []\n",
    "        for i in range(len(pixels)):\n",
    "            features.append(pixels[i])\n",
    "\n",
    "        features = np.array(features)\n",
    "        features = features.reshape(features.shape[0], 224, 224, 3)\n",
    "        features = features / 255\n",
    "\n",
    "        return round(sum(attractiveness_model.predict(features)/len(features))[0],2)\n",
    "    \n",
    "    def is_flag_emoji(self, c):\n",
    "        \n",
    "        return \"\\U0001F1E6\\U0001F1E8\" <= c <= \"\\U0001F1FF\\U0001F1FC\" or c in [\"\\U0001F3F4\\U000e0067\\U000e0062\\U000e0065\\U000e006e\\U000e0067\\U000e007f\", \"\\U0001F3F4\\U000e0067\\U000e0062\\U000e0073\\U000e0063\\U000e0074\\U000e007f\", \"\\U0001F3F4\\U000e0067\\U000e0062\\U000e0077\\U000e006c\\U000e0073\\U000e007f\"]\n",
    "\n",
    "    def deEmojify(self, text):\n",
    "        \n",
    "        regrex_pattern = re.compile(pattern = \"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  \n",
    "            u\"\\U0001F680-\\U0001F6FF\"  \n",
    "            u\"\\U0001F1E0-\\U0001F1FF\" \n",
    "                               \"]+\", flags = re.UNICODE)\n",
    "        \n",
    "        return regrex_pattern.sub(r'',text)\n",
    "\n",
    "    def give_emoji_free_text(self, text):\n",
    "        \n",
    "        allchars = [str for str in text]\n",
    "        emoji_list = [c for c in allchars if c in emoji.UNICODE_EMOJI['en']]\n",
    "        clean_text = ' '.join([str for str in text.split() if not any(i in str for i in emoji_list)])\n",
    "        return clean_text\n",
    "    \n",
    "    def tokenization(self, text):    \n",
    "        \n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        try:\n",
    "            token = []\n",
    "            stops = stopwords.words('english')\n",
    "\n",
    "            emojis = list(set([c for c in text if c in emoji.UNICODE_EMOJI['en']]))\n",
    "            flag_emojis = [c for c in text if self.is_flag_emoji(c) == True]\n",
    "            flags = list(set([i+j for i,j in zip(flag_emojis[::2], flag_emojis[1::2])]))\n",
    "            not_text = emojis + flags\n",
    "\n",
    "            text = self.deEmojify(text)\n",
    "            clean_text = self.give_emoji_free_text(text).replace(',', '').replace('.', '').replace(':','').lower().split()\n",
    "\n",
    "            for i in clean_text:\n",
    "                word, tag = pos_tag(word_tokenize(i))[0]\n",
    "                wntag = tag[0].lower()\n",
    "                wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "\n",
    "                if not wntag:\n",
    "                    lemma = word\n",
    "                    if lemma not in stops:\n",
    "                        token.append(lemma) \n",
    "                else:\n",
    "                    lemma = lemmatizer.lemmatize(word, wntag)\n",
    "                    if lemma not in stops:\n",
    "                        token.append(lemma)\n",
    "\n",
    "            return list(set(token))+emojis+flags\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def get_bigrams(self, bio):\n",
    "        \n",
    "        translator = Translator(service_urls=['translate.googleapis.com'])\n",
    "        bigram_meas = BigramAssocMeasures()\n",
    "\n",
    "        bio_translated = translator.translate(bio).text\n",
    "        words = self.tokenization(bio_translated)\n",
    "        \n",
    "        bio_finder = BigramCollocationFinder.from_words(words)\n",
    "        bio_scored = bio_finder.score_ngrams(bigram_meas.raw_freq)\n",
    "\n",
    "        bg = list(map(lambda x: x[0][0] + '_' + x[0][1], bio_scored))\n",
    "        bio_scores = list(map(lambda x: x[1], bio_scored))\n",
    "        bigrams = list(zip(bg, bio_scores))\n",
    "\n",
    "        return bigrams\n",
    "\n",
    "    def cosine_similarity(self, a, b):\n",
    "        \n",
    "        vec1 = Counter(a)\n",
    "        vec2 = Counter(b)\n",
    "\n",
    "        intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "        numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "        sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "        sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "        denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "        if not denominator:\n",
    "            return 0.0\n",
    "        \n",
    "        return float(numerator) / denominator\n",
    "                                 \n",
    "    def match_report(self, links, name, age, location, distance, education, school, job, orientation, likes, s_likes, desc, p_len, spotify, artist, song, verif, sup_like, insta, tag, atr_score, bio_score, profile_score):\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        color = colors()\n",
    "        \n",
    "        atr_score = (atr_score/5)*2\n",
    "        bio_score = bio_score*1.75\n",
    "        profile_score = profile_score*1.25\n",
    "        \n",
    "        score_general = atr_score + bio_score + profile_score \n",
    "        \n",
    "        print('------------------------------------------------')\n",
    "        data = [[bio_score, atr_score, profile_score, score_general]]\n",
    "        df = pd.DataFrame(data, columns=[\"bio_score\", \"photos_score\", \"profile_score\", \"ovr_score\"])    \n",
    "\n",
    "        fig = plt.figure(figsize=(3,1))\n",
    "\n",
    "        if score_general > 2.35:\n",
    "            ax = fig.add_subplot(1, 2, 1)\n",
    "            img = mpimg.imread('like.jpg')\n",
    "            imgplot = ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax = fig.add_subplot(1, 2, 1)\n",
    "            img = mpimg.imread('dislike.jpg')\n",
    "            imgplot = ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "\n",
    "        ax = fig.add_subplot(1, 2, 2)\n",
    "        ax.text(0.1, 0.85,print(df), clip_on=True)\n",
    "        ax.axis('off')\n",
    "\n",
    "        print('------------------------------------------------')\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        self.plot_images(p_len, tag)\n",
    "\n",
    "        print(f\"{color.BOLD}Face photos: {color.END}{p_len}\")\n",
    "        print()\n",
    "\n",
    "        print(f\"{color.BOLD}Name: {color.END}{name}\")\n",
    "        print()\n",
    "\n",
    "        print(f\"{color.BOLD}Age:{color.END} {age}\")\n",
    "        print()\n",
    "\n",
    "        print(f\"{color.BOLD}Location: {color.END}{location}\")\n",
    "        print(f\"{color.BOLD}Distance (km): {color.END}{distance}\")\n",
    "        print(f\"{color.BOLD}School: {color.END}{school}\")\n",
    "        print(f\"{color.BOLD}Job: {color.END}{job}\")\n",
    "        print(f\"{color.BOLD}Orientation: {color.END}{orientation}\")\n",
    "        print()\n",
    "\n",
    "        print(f\"{color.BOLD}Similar likes: {color.END} {s_likes}\")\n",
    "        print()\n",
    "\n",
    "        print(f\"{color.BOLD}Likes: {color.END} {likes}\")\n",
    "        print()\n",
    "\n",
    "        print(f\"{color.BOLD}Description {color.END}\")\n",
    "        print(desc)\n",
    "        print()\n",
    "\n",
    "        print(f'{color.BOLD}Verified:{color.END} {verif}')\n",
    "        print()\n",
    "\n",
    "        print(f'{color.BOLD}Super liked me:{color.END} {sup_like}')\n",
    "        print()\n",
    "\n",
    "        print(f'{color.BOLD}Instagram:{color.END} {insta}')\n",
    "        print()\n",
    "\n",
    "        print(f'{color.BOLD}Spotify:{color.END} {spotify}')\n",
    "        print(f'{color.BOLD}Artist:{color.END} {artist}')\n",
    "        print(f'{color.BOLD}Song:{color.END} {song}')\n",
    "        print()\n",
    "        \n",
    "        return score_general\n",
    "    \n",
    "    def prepare(self, my_bio):\n",
    "        \n",
    "        points = 0\n",
    "        self.back_to_swipe()\n",
    "        self.info_button()\n",
    "        sleep(5)\n",
    "        \n",
    "        actions = ActionChains(self.driver)\n",
    "        sopa = BeautifulSoup(self.driver.page_source, 'lxml')\n",
    "        sleep(0.3)\n",
    "        \n",
    "        photo_len = self.get_photo_len(sopa)\n",
    "        \n",
    "        sleep(0.5)\n",
    "        name = self.get_name(sopa)\n",
    "        sleep(0.1)\n",
    "        age = self.get_age(sopa)\n",
    "        sleep(0.1)\n",
    "        informacion = self.get_info(sopa)\n",
    "        sleep(0.7)\n",
    "\n",
    "        info = dict.fromkeys(['location', 'distance', 'education', 'school', 'job', 'orientation'], None)\n",
    "\n",
    "        for i in range(len(informacion)):\n",
    "            if 'Lives in' in informacion[i]:\n",
    "                info['location'] = informacion[i].replace('Lives in ','')\n",
    "            if 'kilometers away' in informacion[i]:\n",
    "                info['distance'] = informacion[i].replace('kilometers away','')\n",
    "            if education in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "                info['school'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "            if work in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "                info['job'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "            if gender in str(sopa.select('div [class=\"Row\"]')[i]):\n",
    "                info['orientation'] = sopa.select('div [class=\"Row\"]')[i].text\n",
    "\n",
    "        location = info['location']\n",
    "        \n",
    "        distance = info['distance']\n",
    "        if int(distance) <= 10:\n",
    "            points+=1\n",
    "            \n",
    "        school = info['school']\n",
    "        job = info['job']\n",
    "        orientation = info['orientation']\n",
    "\n",
    "        description = self.get_description(sopa)\n",
    "        likes = self.get_likes(sopa)\n",
    "        \n",
    "        similar_likes = self.get_similar_likes(sopa)\n",
    "        if similar_likes != None:\n",
    "            points+=1\n",
    "        \n",
    "        sleep(0.1)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H-%M-%S\")\n",
    "        id_tag = f\"{name[0]}-{age}_{current_time}\"\n",
    "\n",
    "        photo_links = self.scrap_photos(photo_len)\n",
    "        sleep(2)\n",
    "        self.save_images(photo_links, id_tag)\n",
    "        sleep(2)\n",
    "        \n",
    "        new_photo_len = self.check_missing_photos(photo_len, id_tag)\n",
    "        if new_photo_len > 3:\n",
    "            points+=1\n",
    "        \n",
    "        new_photo_len = self.create_num_face(id_tag)\n",
    "        \n",
    "        verif = self.verified(sopa)\n",
    "        \n",
    "        if verif == True:\n",
    "            points+=1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        sup_like = self.super_like(sopa)\n",
    "        insta = self.get_instagram(sopa)\n",
    "\n",
    "        music = dict.fromkeys(['spotify', 'artist', 'song'], False)\n",
    "\n",
    "        if self.get_spotify(sopa) == True:\n",
    "            music['spotify'] = True\n",
    "            music['artist'] = self.get_artist(sopa)\n",
    "            music['song'] = self.get_song(sopa)\n",
    "\n",
    "        spotify = music['spotify']\n",
    "        artist = music['artist']\n",
    "        song = music['song']\n",
    "\n",
    "        if not(spotify or insta):\n",
    "            pass\n",
    "        else:\n",
    "            points+=1\n",
    "        \n",
    "        desc_score = self.cosine_similarity(my_bio, self.get_bigrams(description))\n",
    "        atr_score = self.attractiveness_score(id_tag)\n",
    "        profile_score = points/5\n",
    "        \n",
    "        ovr_score = self.match_report(photo_links, name, age, location, distance, education, school, job, orientation, likes, similar_likes, description, new_photo_len, spotify, artist, song, verif, sup_like, insta, id_tag, atr_score, desc_score, profile_score)\n",
    "        self.delete_images(id_tag)\n",
    "        \n",
    "        self.info_out()\n",
    "\n",
    "        if ovr_score > 2.15:\n",
    "            self.like_button()\n",
    "            self.no_super_like()\n",
    "            self.close_match()\n",
    "        else:\n",
    "            self.dislike_button()\n",
    "\n",
    "        return name, age, new_photo_len, school, job, orientation, location, distance, similar_likes, likes, description, verif, sup_like, insta, spotify, artist, song, atr_score, desc_score, id_tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bot swiping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = TinderBot()\n",
    "bot.login()\n",
    "df = pd.DataFrame(columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bio = bot.get_my_bio()\n",
    "my_bigrams = bot.get_bigrams(my_bio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swipes = int(input('How many swipes would you like to go through?')) \n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    if count == swipes:\n",
    "        break\n",
    "    else:\n",
    "    new_match = bot.prepare(my_bio)\n",
    "    this_df = pd.DataFrame(list([new_match]), columns = cols)\n",
    "    df = df.append(this_df, ignore_index = True)\n",
    "    df.head()\n",
    "    \n",
    "bot.driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
